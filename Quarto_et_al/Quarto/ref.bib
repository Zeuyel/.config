@article{abubakarEffectivenessVerticalError2023,
  title = {Effectiveness of Vertical Error Budget Model for Portable Multi-Beam Echo-Sounder in Shallow Water Bathymetric Survey},
  author = {Abubakar, Aa and {Poerbandono}},
  year = {2023},
  month = sep,
  journal = {IOP Conference Series: Earth and Environmental Science},
  volume = {1245},
  number = {1},
  pages = {012041},
  issn = {1755-1307, 1755-1315},
  doi = {10.1088/1755-1315/1245/1/012041},
  urldate = {2023-10-14},
  abstract = {With the increasing availability of portable survey equipment and platforms, hydrographic data acquisition now offers a diverse range of device options and installation methods. Tailoring the mounting and installation of hydrographic survey devices to fit the boat or platform dimensions has become common practice. The use of portable equipment is essential, given the wide selection of combined options available in the market. Consequently, sensor offsets and device performance differ for each survey conducted, necessitating the constant verification of accuracy performance.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\8JEHN5BZ\Abubakar å’Œ Poerbandono - 2023 - Effectiveness of vertical error budget model for p.pdf}
}

@article{bashiribehmiriIncorporatingAirTemperature2023,
  title = {Incorporating Air Temperature into Mid-Term Electricity Load Forecasting Models Using Time-Series Regressions and Neural Networks},
  author = {Bashiri Behmiri, Niaz and Fezzi, Carlo and Ravazzolo, Francesco},
  year = {2023},
  month = sep,
  journal = {Energy},
  volume = {278},
  pages = {127831},
  issn = {03605442},
  doi = {10.1016/j.energy.2023.127831},
  urldate = {2023-05-20},
  langid = {english},
  lccn = {8.8569},
  file = {C:\Users\Epictus\Zotero\storage\JUXLFM2C\Bashiri Behmiri ç­‰ - 2023 - Incorporating air temperature into mid-term electr.pdf}
}

@article{changIntervalValuedTimeSeries2022,
  title = {An {{Interval-Valued Time Series Forecasting Scheme With Probability Distribution Features}} for {{Electric Power Generation Prediction}}},
  author = {Chang, Ting-Jen and Lee, Samantha and Lee, Jonathan and Lu, Chi-Jie},
  year = {2022},
  journal = {IEEE Access},
  volume = {10},
  pages = {6417--6429},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3142083},
  urldate = {2023-03-05},
  abstract = {Developing an effective interval-valued time series (ITS) forecasting scheme for electric power generation is an important issue for energy operators and governments when making energy strategic decisions. The existing studies for ITS forecasting only consider basic descriptive information such as center, radius, upper and lower bounds, and overlooks the distribution information within the data interval. In this study, an interval-valued time series forecasting scheme based on probability distribution information features of interval-valued data with machine learning algorithms is proposed to enhance electric power generation forecasting. In the proposed scheme, the central tendency features and dispersion features from the interval-valued data are designed as integrated features sets (IFS) and used as predictor variables. Three methods including supper vector regression and extreme learning machine and multivariate adaptive regression splines based on the IFS are utilized to develop ITS forecasting models. The daily time series of the metered generation from the Australian Energy Market Operator is used to illustrate the proposed scheme. Empirical results show that the proposed ITS forecasting schemes with IFS outperform the eight benchmark models and thus validate that the proposed scheme is an effective alternative for interval-valued electric power generation forecasting.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\PTWHCC3R\Chang ç­‰ - 2022 - An Interval-Valued Time Series Forecasting Scheme .pdf}
}

@inproceedings{chenLearningRotateQuaternion2022,
  title = {Learning to {{Rotate}}: {{Quaternion Transformer}} for {{Complicated Periodical Time Series Forecasting}}},
  shorttitle = {Learning to {{Rotate}}},
  booktitle = {Proceedings of the 28th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Chen, Weiqi and Wang, Wenwei and Peng, Bingqing and Wen, Qingsong and Zhou, Tian and Sun, Liang},
  year = {2022},
  month = aug,
  pages = {146--156},
  publisher = {{ACM}},
  address = {{Washington DC USA}},
  doi = {10.1145/3534678.3539234},
  urldate = {2023-09-16},
  abstract = {Time series forecasting is a critical and challenging problem in many real applications. Recently, Transformer-based models prevail in time series forecasting due to their advancement in long-range dependencies learning. Besides, some models introduce series decomposition to further unveil reliable yet plain temporal dependencies. Unfortunately, few models could handle complicated periodical patterns, such as multiple periods, variable periods, and phase shifts in real-world datasets. Meanwhile, the notorious quadratic complexity of dot-product attentions hampers long sequence modeling. To address these challenges, we design an innovative framework Quaternion Transformer (Quatformer), along with three major components: 1). learning-to-rotate attention (LRA) based on quaternions which introduces learnable period and phase information to depict intricate periodical patterns. 2). trend normalization to normalize the series representations in hidden layers of the model considering the slowly varying characteristic of trend. 3). decoupling LRA using global memory to achieve linear complexity without losing prediction accuracy. We evaluate our framework on multiple real-world time series datasets and observe an average 8.1\% and up to 18.5\% MSE improvement over the best state-of-the-art baseline.},
  isbn = {978-1-4503-9385-0},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\E6YMFNK2\Chen ç­‰ - 2022 - Learning to Rotate Quaternion Transformer for Com.pdf}
}

@article{cuiExplorationDualattentionMechanismbased2023,
  title = {Exploration of Dual-Attention Mechanism-Based Deep Learning for Multi-Step-Ahead Flood Probabilistic Forecasting},
  author = {Cui, Zhen and Guo, Shenglian and Zhou, Yanlai and Wang, Jun},
  year = {2023},
  month = jul,
  journal = {Journal of Hydrology},
  volume = {622},
  pages = {129688},
  issn = {00221694},
  doi = {10.1016/j.jhydrol.2023.129688},
  urldate = {2023-05-27},
  abstract = {In order to improve the flood forecasting accuracy and reflect the forecast uncertainty information in the Three Gorges Reservoir (TGR) interval-basin in China, this study integrates the feature and temporal dual-attention (DA) mechanism and recursive encoder-decoder (RED) structure into the long short-term memory (LSTM) neural network to develop a DA-LSTM-RED model. The feature attention acts on the input variables of the encoder, and the temporal attention mechanism acts on the hidden layer states extracted by the LSTM neural network during encoding process, prompting the proposed model to extract critical input information among different types and moments of input variables to improve the multi-step-ahead flood forecasting accuracy. Second, the copula-based Hydrological Uncertainty Processor (copula-HUP) is used to quantify the forecast uncertainty of the proposed model meanwhile creating multi-step-ahead flood probabilistic forecasts. Combining the long-term 6 h hydrologic data series of the Xiangjiaba-TGR interval-basin and the forecasted precipitation from the European Centre for Medium-Range Weather Forecasts (ECMWF), the effectiveness of the proposed model, the effect of forecast precipitation on multi-step-ahead flood forecasting, and the effect of different copula functions on the probabilistic forecast of copula-HUP are investigated, respectively. The results show that the DALSTM-RED model can effectively improve the forecasting accuracy for long forecast horizons (3-7d) compared to the LSTM-RED model, and the average absolute error metrics are reduced by 10\%-17\%. Meanwhile, the proposed model can identify input variables with a high correlation with the target output variables, which improves the interpretability of deep learning to a certain extent. The Student copula-HUP has the lowest RB and CRPS metrics than the Frank and Gaussian copula-HUP, which can better quantify the DA-LSTM-RED model's forecast un\- certainty. Therefore, combining the proposed model with the Student copula-HUP can effectively reduce the forecasting uncertainty, enhance the forecasting reliability and accuracy for future horizons, and provide reliable risk information for the TGR flood control scheduling decision.},
  copyright = {6.7309},
  langid = {english},
  lccn = {6.7085},
  file = {C:\Users\Epictus\Zotero\storage\BEDIMTWU\Cui ç­‰ - 2023 - Exploration of dual-attention mechanism-based deep.pdf}
}

@article{cuiMcVCsBNewHybrid2023,
  title = {{{McVCsB}}: {{A}} New Hybrid Deep Learning Network for Stock Index Prediction},
  shorttitle = {{{McVCsB}}},
  author = {Cui, Chenhao and Wang, Peiwan and Li, Yong and Zhang, Yuzhe},
  year = {2023},
  month = dec,
  journal = {Expert Systems with Applications},
  volume = {232},
  pages = {120902},
  issn = {09574174},
  doi = {10.1016/j.eswa.2023.120902},
  urldate = {2023-07-09},
  abstract = {Forecasting the stock composite index is a challenge on account of the abundant noise-induced high degree of non-linearity and non-stationarity. Numerous predictive models based on statistical and intelligent methods have been proposed but using a single model or method cannot afford noise reduction so as to achieve credible results in facilitating regulation and investment. This study presents a novel hybrid model of multi-channel VMD-CBAM-BiLSTM named McVCsB based on an improved decomposition-reconstruction predicting framework for stock index prediction. The variational modal decomposition algorithm (VMD) and convolutional block attention module (CBAM) are adopted to achieve noise filtration and deep-level feature extraction. The denoised and concentrated feature will feed the predicting mechanism of bi-directional longshort-term networks (BiLSTM) to produce a stock index for the next day. The multi-channel input structure is innovated to resolve the inherent cumulative error problem of the decomposition-reconstruction framework by changing the parallel processing manner. We design three levels of model comparison by selecting and constructing a variety of benchmark models. In both statistical and practical assessments, the proposed model outperforms others with high reliability and robustness. According to the empirical results on four stock composite indexes, the McVCsB gives the best performance on China's SCI out-of-sample prediction with the mean absolute error of 0.0016, root mean square error of 0.0019, symmetric mean absolute percentage error of 0.3862, R2 of 0.9989 and Sharpe ratio of 0.6648. Thus, this new proposed model provides an effective predicting tool and can be extensively applied to stock markets in a more widen range.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\XF7QTYI3\Cui ç­‰ - 2023 - McVCsB A new hybrid deep learning network for sto.pdf}
}

@misc{dasLongtermForecastingTiDE2023,
  title = {Long-Term {{Forecasting}} with {{TiDE}}: {{Time-series Dense Encoder}}},
  shorttitle = {Long-Term {{Forecasting}} with {{TiDE}}},
  author = {Das, Abhimanyu and Kong, Weihao and Leach, Andrew and Mathur, Shaan and Sen, Rajat and Yu, Rose},
  year = {2023},
  month = apr,
  number = {arXiv:2304.08424},
  eprint = {2304.08424},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-05-01},
  abstract = {Recent work has shown that simple linear models can outperform several Transformer based approaches in long term time-series forecasting. Motivated by this, we propose a Multi-layer Perceptron (MLP) based encoder-decoder model, Time-series Dense Encoder (TiDE), for long-term time-series forecasting that enjoys the simplicity and speed of linear models while also being able to handle covariates and non-linear dependencies. Theoretically, we prove that the simplest linear analogue of our model can achieve near optimal error rate for linear dynamical systems (LDS) under some assumptions. Empirically, we show that our method can match or outperform prior approaches on popular long-term time-series forecasting benchmarks while being 5-10x faster than the best Transformer based model.},
  archiveprefix = {arxiv},
  file = {C\:\\Users\\Epictus\\Zotero\\storage\\AIAEIBV2\\Das et al_2023_Long-term Forecasting with TiDE.pdf;C\:\\Users\\Epictus\\Zotero\\storage\\MALXF8AS\\2304.html}
}

@article{delgado-bonalApproximateEntropySample2019,
  title = {Approximate {{Entropy}} and {{Sample Entropy}}: {{A Comprehensive Tutorial}}},
  shorttitle = {Approximate {{Entropy}} and {{Sample Entropy}}},
  author = {{Delgado-Bonal}, Alfonso and Marshak, Alexander},
  year = {2019},
  month = may,
  journal = {Entropy},
  volume = {21},
  number = {6},
  pages = {541},
  issn = {1099-4300},
  doi = {10.3390/e21060541},
  urldate = {2023-03-05},
  abstract = {Approximate Entropy and Sample Entropy are two algorithms for determining the regularity of series of data based on the existence of patterns. Despite their similarities, the theoretical ideas behind those techniques are different but usually ignored. This paper aims to be a complete guideline of the theory and application of the algorithms, intended to explain their characteristics in detail to researchers from different fields. While initially developed for physiological applications, both algorithms have been used in other fields such as medicine, telecommunications, economics or Earth sciences. In this paper, we explain the theoretical aspects involving Information Theory and Chaos Theory, provide simple source codes for their computation, and illustrate the techniques with a step by step example of how to use the algorithms properly. This paper is not intended to be an exhaustive review of all previous applications of the algorithms but rather a comprehensive tutorial where no previous knowledge is required to understand the methodology.},
  copyright = {2.6418},
  langid = {english},
  lccn = {2.7381},
  file = {C:\Users\Epictus\Zotero\storage\ET3TXVMS\Delgado-Bonal_Marshak_2019_Approximate Entropy and Sample Entropy.pdf}
}

@misc{dengLearningStructuredComponents2023,
  title = {Learning {{Structured Components}}: {{Towards Modular}} and {{Interpretable Multivariate Time Series Forecasting}}},
  shorttitle = {Learning {{Structured Components}}},
  author = {Deng, Jinliang and Chen, Xiusi and Jiang, Renhe and Yin, Du and Yang, Yi and Song, Xuan and Tsang, Ivor W.},
  year = {2023},
  month = may,
  number = {arXiv:2305.13036},
  eprint = {2305.13036},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-05-27},
  abstract = {Multivariate time-series (MTS) forecasting is a paramount and fundamental problem in many real-world applications. The core issue in MTS forecasting is how to effectively model complex spatial-temporal patterns. In this paper, we develop a modular and interpretable forecasting framework, which seeks to individually model each component of the spatial-temporal patterns. We name this framework SCNN, short for Structured Component-based Neural Network. SCNN works with a pre-defined generative process of MTS, which arithmetically characterizes the latent structure of the spatial-temporal patterns. In line with its reverse process, SCNN decouples MTS data into structured and heterogeneous components and then respectively extrapolates the evolution of these components, the dynamics of which is more traceable and predictable than the original MTS. Extensive experiments are conducted to demonstrate that SCNN can achieve superior performance over state-of-the-art models on three real-world datasets. Additionally, we examine SCNN with different configurations and perform in-depth analyses of the properties of SCNN.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\Epictus\\Zotero\\storage\\PDYKLY38\\Deng et al_2023_Learning Structured Components.pdf;C\:\\Users\\Epictus\\Zotero\\storage\\YBIBBI5S\\2305.html}
}

@article{dingForecastingSalesStock2021,
  title = {Forecasting the Sales and Stock of Electric Vehicles Using a Novel Self-Adaptive Optimized Grey Model},
  author = {Ding, Song and Li, Ruojin},
  year = {2021},
  month = jan,
  journal = {Engineering Applications of Artificial Intelligence},
  doi = {10.1016/j.engappai.2020.104148},
  abstract = {{$<$}p{$>$}To alleviate the threatening pressure of energy shortage and environmental issues, the adoption of electric vehicles (EVs) is regarded as an effective measure. Therefore, accurate predictions of EVs sales and stock are crucial to deploying charging infrastructures, improving industrial policies, and providing credible references of the renewable sources demand in the transportation system. To this end, a new self-adaptive optimized grey model is proposed with the following improvements: first, a dynamic weighted sequence is generated to extract more value from the available observations by sufficiently highlighting the new data without information lapses. Second, the weighted coefficient and modified initial condition can adjust to various samples and thus augment the applicability of the proposed model. Third, Simpson's formula is utilized to reconstruct the background value and then integrated with the modified initial condition to smooth the data saltations and further enhance the forecasting precision. To validate the rationality and efficacy of the novel model, four cases regarding the sales and stock of EVs are simulated by the proposed model compared with six benchmarks. As demonstrated in the empirical results, the novel model performs with the highest forecasting precision in most cases, which reveals that the optimization techniques exerted on the initial condition and background value can strikingly enhance the adaptability and prediction accuracy of the grey model. Thus, the novel model can be regarded as a promising tool for EVs prediction.{$<$}/p{$>$}},
  copyright = {6.6936},
  lccn = {7.8024},
  file = {C:\Users\Epictus\Zotero\storage\CR8Z5AIZ\Ding_Li_2021_Forecasting the sales and stock of electric vehicles using a novel.pdf}
}

@article{dingIntegratingDataDecomposition2022,
  title = {Integrating Data Decomposition and Machine Learning Methods: {{An}} Empirical Proposition and Analysis for Renewable Energy Generation Forecasting},
  author = {Ding, Song and Zhang, Huahan and Tao, Zui and Li, Ruojin},
  year = {2022},
  month = may,
  journal = {Expert Systems with Applications},
  doi = {10.1016/j.eswa.2022.117635},
  abstract = {{$<$}p{$>$}Renewable energy generation (REG) has been vigorously developed under the dual pressure of environmental contamination and fossil fuel energy shortage. Whereas the rapidly increasing REG instigates stochastic volatility may threaten the REG deployment and grid stability. Motivated by the grid flexibility enhancement depending on the expansion of grid infrastructure that belongs to the mid-term management domain, the precise predictions for mid-term, especially monthly REG sourced from diverse renewable energy, are indispensable for power plant configuration, electricity end-uses promotion, and grid expansion to propel the energy system transformation. To this end, aiming at diverse monthly REG datasets characterized by periodicity, nonlinearity, and volatility, the seasonal-trend decomposition procedure based on loess ({$<$}em{$>$}STL{$<$}/em{$>$}) is initially employed to extract the trend and periodic features of monthly REG datasets, and generate trend, seasonal, and remainder subseries. Based on the decomposed data, long-short term memory ({$<$}em{$>$}LSTM{$<$}/em{$>$}) is utilized for subseries prediction, and then the projections are integrated to compose the ultimate forecasted results for original REG observations. To validate the efficacy and adaptability of the proposed data-driven {$<$}em{$>$}STL-LSTM{$<$}/em{$>$} framework, several machine learning methods and autoregressive models are involved in predicting practical monthly electricity generation datasets sourced by solar, wind, hydropower, and geothermal energy in different countries. The forecasted results indicate that the proposed framework is demonstrated with superlative prediction performance and strong adaptability for generation prediction derived from diverse renewable energy. Therefore, the novel {$<$}em{$>$}STL-LSTM{$<$}/em{$>$} framework may constitute a promising alternative for REG forecasting.{$<$}/p{$>$}}
}

@article{dingNewMultivariableGrey2020,
  title = {A {{New Multivariable Grey Convolution Model Based}} on {{Simpson}}'s {{Rule}} and {{Its Applications}}},
  author = {Ding, Song and Li, Ruojin},
  year = {2020},
  month = feb,
  journal = {Complexity},
  doi = {10.1155/2020/4564653},
  abstract = {Accurate estimations can provide a solid basis for decision-making and policy-making that have experienced some kind of complication and uncertainty. Accordingly, a multivariable grey convolution model (GMC (1, \emph{n})) having correct solutions is put forward to deal with such complicated and uncertain issues, instead of the incorrect multivariable grey model (GM (1, \emph{n})). However, the conventional approach to computing background values of the GMC (1, \emph{n}) model is inaccurate, and this model's forecasting accuracy cannot be expected. Thereby, the drawback analysis of the GMC (1, \emph{n}) model is conducted with mathematical reasoning, which can explain why this model is inaccurate in some applications. In order to eliminate the drawbacks, a new optimized GMC (1, \emph{n}), shorted for OGMC (1, \emph{n}), is proposed, whose background values are calculated based on Simpson' rule that is able to efficiently approximate the integration of a function. Furthermore, its extended version that uses the Gaussian rule to discretize the convolution integral, abbreviated as OGMC\textsubscript{G} (1, \emph{n}), is proposed to further enhance the model's forecasting ability. In general, these two optimized models have such advantages as simplified structure, consistent forecasting performance, and satisfactory efficiency. Three empirical studies are carried out for verifying the above advantages of the optimized model, compared with the conventional GMC (1, \emph{n}), GMC\textsubscript{G} (1, \emph{n}), GM (1, \emph{n}), and DGM (1, \emph{n}) models. Results show that the new background values can effectively be calculated based on Simpson's rule, and the optimized models significantly outperform other competing models in most cases.},
  copyright = {2.2128},
  lccn = {2.1208},
  file = {C:\Users\Epictus\Zotero\storage\556VCTGP\Ding_Li_2020_A New Multivariable Grey Convolution Model Based on Simpsonâ€™s Rule and Its.pdf}
}

@article{dingNovelSeasonalAdaptive2022,
  title = {A Novel Seasonal Adaptive Grey Model with the Data-Restacking Technique for Monthly Renewable Energy Consumption Forecasting},
  author = {Ding, Song and Tao, Zui and Li, Ruojin and Qin, Xinghuan},
  year = {2022},
  month = jul,
  journal = {Expert Systems with Applications},
  doi = {10.1016/j.eswa.2022.118115},
  abstract = {{$<$}p{$>$}To provide accurate renewable energy forecasts that adapt to the country's sustainable development, a novel seasonal model combined with the data-restacking technique is proposed in this paper. Specifically, the data-restacking technique is initially utilized to eliminate the seasonal fluctuations of the collected observations, which can eliminate the fundamental flaws in conventional seasonal grey models. Subsequently, the time function term is originally designed to incorporate into the dynamic structure to reflect the cumulative time effects, which can smoothly describe the dynamic changes and significantly improve the robustness of the novel model. Further, the self-adaptive parameters optimized using particle{$<$}!-- --{$>~<$}!-- --{$>$}swarm{$<$}!-- --{$>~<$}!-- --{$>$}optimization can effectively enhance the adaptability and generalization of the proposed model. For elaboration and verification purposes, experiments on forecasting American monthly renewable energy consumption in the commercial sector and industrial solar energy have been implemented compared to a range of benchmark models, including other prevalent grey prediction models, statistical approaches, and machine learning methods. Experimental results demonstrate that this new model presents more successful outcomes than the other benchmarks in overall and restacking performance.{$<$}/p{$>$}}
}

@article{dufloSchoolingLaborMarket,
  title = {Schooling and {{Labor Market Consequences}} of {{School Construction}} in {{Indonesia}}: {{Evidence}} from an {{Unusual Policy Experiment}}},
  author = {DuFLo, {\relax ESTHER}},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\DGALD4TP\DuFLo - Schooling and Labor Market Consequences of School .pdf}
}

@inproceedings{ekambaramTSMixerLightweightMLPMixer2023,
  title = {{{TSMixer}}: {{Lightweight MLP-Mixer Model}} for {{Multivariate Time Series Forecasting}}},
  shorttitle = {{{TSMixer}}},
  booktitle = {Proceedings of the 29th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Ekambaram, Vijay and Jati, Arindam and Nguyen, Nam and Sinthong, Phanwadee and Kalagnanam, Jayant},
  year = {2023},
  month = aug,
  pages = {459--469},
  publisher = {{ACM}},
  address = {{Long Beach CA USA}},
  doi = {10.1145/3580305.3599533},
  urldate = {2023-09-14},
  abstract = {Transformers have gained popularity in time series forecasting for their ability to capture long-sequence interactions. However, their memory and compute-intensive requirements pose a critical bottleneck for long-term forecasting, despite numerous advancements in compute-aware self-attention modules. To address this, we propose TSMixer, a lightweight neural architecture exclusively composed of multi-layer perceptron (MLP) modules. TSMixer is designed for multivariate forecasting and representation learning on patched time series, providing an efficient alternative to Transformers. Our model draws inspiration from the success of MLP-Mixer models in computer vision. We demonstrate the challenges involved in adapting Vision MLP-Mixer for time series and introduce empirically validated components to enhance accuracy. This includes a novel design paradigm of attaching online reconciliation heads to the MLPMixer backbone, for explicitly modeling the time-series properties such as hierarchy and channel-correlations. We also propose a Hybrid channel modeling approach to effectively handle noisy channel interactions and generalization across diverse datasets, a common challenge in existing patch channel-mixing methods. Additionally, a simple gated attention mechanism is introduced in the backbone to prioritize important features. By incorporating these lightweight components, we significantly enhance the learning capability of simple MLP structures, outperforming complex Transformer models with minimal computing usage. Moreover, TSMixer's modular design enables compatibility with both supervised and masked self-supervised learning methods, making it a promising building block for time-series Foundation Models. TSMixer outperforms state-of-the-art MLP and Transformer models in forecasting by a considerable margin of 8-60\%. It also outperforms the latest strong benchmarks of Patch-Transformer models (by 1-2\%) with a significant reduction in memory and runtime (2-3X).},
  isbn = {9798400701030},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\LZ4HVA2G\Ekambaram ç­‰ - 2023 - TSMixer Lightweight MLP-Mixer Model for Multivari.pdf}
}

@article{fagundesIntervalKernelRegression2014,
  title = {Interval Kernel Regression},
  author = {Fagundes, Roberta A.A. and {de Souza}, Renata M.C.R. and Cysneiros, Francisco Jos{\'e} A.},
  year = {2014},
  month = mar,
  journal = {Neurocomputing},
  volume = {128},
  pages = {371--388},
  issn = {09252312},
  doi = {10.1016/j.neucom.2013.08.029},
  urldate = {2023-03-04},
  copyright = {5.4156},
  langid = {english},
  lccn = {5.7787},
  file = {C:\Users\Epictus\Zotero\storage\I35HMTB7\Fagundes et al_2014_Interval kernel regression.pdf}
}

@article{FanJiYuGunDongShiJianChuangDeTanShiChangJieGeFenJieJiChengYuCeYanJiu2023,
  title = {{åŸºäºæ»šåŠ¨æ—¶é—´çª—çš„ç¢³å¸‚åœºä»·æ ¼åˆ†è§£é›†æˆé¢„æµ‹ç ”ç©¶}},
  author = {èŒƒ, ä¸½ä¼Ÿ and è‘£, æ¬¢æ¬¢ and æ¸, ä»¤},
  year = {2023},
  journal = {ä¸­å›½ç®¡ç†ç§‘å­¦},
  volume = {31},
  number = {1},
  pages = {277--286},
  issn = {1003-207X},
  doi = {10.16381/j.cnki.issn1003-207x.2022.0122},
  abstract = {æé«˜ç¢³å¸‚åœºä»·æ ¼é¢„æµ‹å‡†ç¡®æ€§å¯¹äºäº¤æ˜“é£é™©ç›‘æµ‹ä»¥åŠç¢³å¸‚åœºå¹³ç¨³å‘å±•å…·æœ‰é‡è¦ä»·å€¼ã€‚é’ˆå¯¹å¤æ‚çš„ã€éçº¿æ€§ç¢³å¸‚åœºä»·æ ¼æ•°æ®çš„çŸ­æœŸé¢„æµ‹è¯¯å·®åå¤§ã€åˆ†è§£è¿‡ç¨‹æ˜“äº§ç”Ÿæ•°æ®æ³„éœ²é—®é¢˜ï¼Œæå‡ºäº†åŸºäºæ»šåŠ¨æ—¶é—´çª—çš„SSA-SVRåˆ†è§£é›†æˆé¢„æµ‹æ¡†æ¶ã€‚é¦–å…ˆï¼Œé€‰å–æ—¶é—´çª—æ•°æ®ï¼Œç»§è€Œå€ŸåŠ©å¥‡å¼‚è°±åˆ†æå°†æ—¶é—´çª—å†…ç¢³ä»·åºåˆ—åˆ†è§£é‡æ„ä¸ºé«˜ã€ä½é¢‘åºåˆ—ï¼›ç„¶åï¼Œä½¿ç”¨æ”¯æŒå‘é‡å›å½’æ–¹æ³•å¯¹é«˜ã€ä½é¢‘åºåˆ—åˆ†åˆ«è¿›è¡Œé¢„æµ‹ï¼›æœ€åï¼ŒåŠ å’Œé›†æˆé¢„æµ‹ç»“æœï¼Œå¾—åˆ°ä¸‹ä¸€æ—¶åˆ»çš„ç¢³å¸‚åœºä»·æ ¼é¢„æµ‹å€¼ã€‚é€šè¿‡ä¸æ–­æ›´æ–°æ—¶é—´çª—çš„æ•°æ®å†…å®¹ï¼ŒåŠ¨æ€æ‰§è¡Œ``åˆ†è§£-é¢„æµ‹-é›†æˆ''è¿‡ç¨‹ï¼Œå®ç°ç¢³å¸‚åœºä»·æ ¼çš„å®æ—¶é¢„æµ‹ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æ‰€æå‡ºæ¡†æ¶è¡¨ç°å‡ºä¼˜å¼‚ä¸”ç¨³å®šçš„é¢„æµ‹æ€§èƒ½ï¼Œåœ¨ç¢³å¸‚åœºä»·æ ¼é¢„æµ‹ç ”ç©¶ä¸­å…·æœ‰è‰¯å¥½çš„é€‚ç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚},
  copyright = {2.002},
  langid = {chinese},
  lccn = {3.661},
  keywords = {mathmatic decompsition},
  annotation = {ğŸ“—{$<$}åŒ—å¤§æ ¸å¿ƒ, CSSCI, CSCD, AMI{$>$}},
  file = {C:\Users\Epictus\Zotero\storage\KZYVEFVD\åŸºäºæ»šåŠ¨æ—¶é—´çª—çš„ç¢³å¸‚åœºä»·æ ¼åˆ†è§£é›†æˆé¢„æµ‹ç ”ç©¶_èŒƒä¸½ä¼Ÿ.pdf}
}

@article{ForecastingCarbonPrice,
  title = {Forecasting Carbon Price Using a Multi-objective Least Squares Support Vector Machine with Mixture Kernels},
  doi = {10.1002/for.2784},
  urldate = {2023-04-08},
  langid = {english}
}

@misc{gamakumaraConditionalNormalizationTime2023,
  title = {Conditional Normalization in Time Series Analysis},
  author = {Gamakumara, Puwasala and {Santos-Fernandez}, Edgar and Talagala, Priyanga Dilini and Hyndman, Rob J. and Mengersen, Kerrie and Leigh, Catherine},
  year = {2023},
  month = may,
  number = {arXiv:2305.12651},
  eprint = {2305.12651},
  primaryclass = {stat},
  publisher = {{arXiv}},
  urldate = {2023-05-27},
  abstract = {Time series often reflect variation associated with other related variables. Controlling for the effect of these variables is useful when modeling or analysing the time series. We introduce a novel approach to normalize time series data conditional on a set of covariates. We do this by modeling the conditional mean and the conditional variance of the time series with generalized additive models using a set of covariates. The conditional mean and variance are then used to normalize the time series. We illustrate the use of conditionally normalized series using two applications involving river network data. First, we show how these normalized time series can be used to impute missing values in the data. Second, we show how the normalized series can be used to estimate the conditional autocorrelation function and conditional cross-correlation functions via additive models. Finally we use the conditional cross-correlations to estimate the time it takes water to flow between two locations in a river network.},
  archiveprefix = {arxiv},
  keywords = {å½’ä¸€åŒ–},
  file = {C\:\\Users\\Epictus\\Zotero\\storage\\C3CL8B84\\Gamakumara et al_2023_Conditional normalization in time series analysis.pdf;C\:\\Users\\Epictus\\Zotero\\storage\\GABP46PZ\\2305.html}
}

@article{grzadzielImportanceUnderKeelSound2021,
  title = {The {{Importance}} of {{Under-Keel Sound Velocity Sensor}} in {{Measuring Water Depth}} with {{Multibeam Echosounder}}},
  author = {Grz{\k{a}}dziel, Artur},
  year = {2021},
  month = aug,
  journal = {Energies},
  volume = {14},
  number = {17},
  pages = {5267},
  issn = {1996-1073},
  doi = {10.3390/en14175267},
  urldate = {2023-10-14},
  abstract = {The basic and most commonly used application of modern multibeam echosounders (MBES) is the bathymetric survey. Surface sound velocity errors introduce errors on beam steering angles and consequently errors in depth and position values. Due to systematic malfunction and troubleshooting of the sound velocity sensor (SVS) on board Polish Navy hydrographic ship Arctowski, attempts to solve the problem were made. All the inspections and cleaning of the sensor were performed with the use of divers or while staying in the shipyard. Diving work did not always bring the expected results and periodic ship docking was quite expensive. The article shows the importance of the SVS sensor in bathymetric measurements using multibeam echosounder. Selected problems of the sensor operation and temporary solutions were presented. The paper provides a description of practical solutions implemented aboard the navy ship Arctowski. The idea and implementation were the result of the author's experience gained during 18 years of service on board that ship.},
  copyright = {3.3000},
  langid = {english},
  lccn = {3.1999}
}

@article{grzadzielMethodTimeEstimation2023,
  title = {Method of {{Time Estimation}} for the {{Bathymetric Surveys Conducted}} with a {{Multi-Beam Echosounder System}}},
  author = {Grz{\k{a}}dziel, Artur},
  year = {2023},
  month = sep,
  journal = {Applied Sciences},
  volume = {13},
  number = {18},
  pages = {10139},
  issn = {2076-3417},
  doi = {10.3390/app131810139},
  urldate = {2023-10-14},
  abstract = {Exact and complete preparation of a hydrographic survey project allows for the avoidance or reduction of additional costs and unexpected delays and, at the same time, increases the efficiency of the survey. One of the essential requirements at the survey planning stage is a calculation of time necessary for performing bathymetric measurements with a multi-beam echosounder. Based on these calculations, many decisions related to the costs and methodology are made. The article presents the method of time estimation for the hydrographic surveys and takes into account many variables that directly affect the final duration of the project. The paper demonstrates the influence of water depth, multi-beam echosounder swath angle, and other planning parameters related to the scheme of survey lines on the total time of stay at sea. The main findings are based on the author's over twenty years of experience aboard the Polish Navy hydrographic ship Arctowski and include thorough analysis of specialist literature, publications, manuals, and international standards.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\W4YAZCLG\GrzÄ…dziel - 2023 - Method of Time Estimation for the Bathymetric Surv.pdf}
}

@article{guoApplicationMultibeamBathymetry2023,
  title = {Application of Multi-Beam Bathymetry System in Shallow Water Area},
  author = {Guo, Qiang and Fu, Chuanyu and Chen, Yikang and Zhang, Yu},
  year = {2023},
  month = feb,
  journal = {Journal of Physics: Conference Series},
  volume = {2428},
  number = {1},
  pages = {012042},
  issn = {1742-6588, 1742-6596},
  doi = {10.1088/1742-6596/2428/1/012042},
  urldate = {2023-10-14},
  abstract = {Multi-beam bathymetry technology plays an important role in ocean, river and lake surveying and mapping. According to the measurement principle and technical requirements of MS8200 multi-beam bathymetry system, this paper introduces the composition and working principle of the system, the installation and calibration of the system, and the data in the postprocessing process, the sea area and terrain characteristics near Wenchang Qinglan Port are taken as the research object to discuss the dual multi-beam bathymetric technology and data processing process, and compare the data of single multi-beam in the same sea area. The research results show that the dual probe of multibeam bathymetry system can better reflect the topographic features of the seafloor compared with the single probe, and shorten the time of mapping, reduce the labor intensity and improve the measurement efficiency, and provide data reference for the stability and reliability evaluation study of the dual probe of multibeam bathymetry system.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\K2VWM8UU\Guo ç­‰ - 2023 - Application of multi-beam bathymetry system in sha.pdf}
}

@article{henriquePracticalMachineLearning2023,
  title = {Practical Machine Learning: {{Forecasting}} Daily Financial Markets Directions},
  shorttitle = {Practical Machine Learning},
  author = {Henrique, Bruno Miranda and Sobreiro, Vinicius Amorim and Kimura, Herbert},
  year = {2023},
  month = jun,
  journal = {Expert Systems with Applications},
  pages = {120840},
  issn = {09574174},
  doi = {10.1016/j.eswa.2023.120840},
  urldate = {2023-07-02},
  abstract = {Financial time series prediction has many applications in economics, but producing profitable strategies certainly has a special place among them, a daunting challenge. Statistical and machine learning techniques are intensively researched in the search for a holy grail of stock markets forecasting. However, it is not clear to prospecting researchers how good those popular models are regarding useful predictions on a real scenario. This paper contributes to that discussion, providing decisive evidences contrary to the use of basic out-of-the-box models, specifically Artificial Neural Networks (ANN), Support Vector Machines (SVM), Random Forest (RF) and Naive-Bayes (NB). Results consider optimistic and unreal variables often found in literature, as well as a more close-to-real simulation of the models usage. Specifically, current day closing prices direction forecasting results are contrasted with those on next day forecasts. As expected, when forecasting the current day, accuracy is almost perfect. However, when used to forecast next day closing direction, with a strict data separation policy and without direction or snooping bias, ANN, SVM, RF and NB produce results essentially equal to random guessing. The main achieved result is the demonstration of how a machine learning approach would fare in a support decision system for forecasting short-term future market direction, regardless of the level of market development, considering more than 100 securities in a 10 years period. Consequences for algorithmic trading relate to discouraging usage of the considered models as implemented here. On a more abstract sense, this paper presents more evidence to the Efficient Market Hypothesis (EMH).},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\MI9TQBRP\Henrique ç­‰ - 2023 - Practical machine learning Forecasting daily fina.pdf}
}

@article{jiangExploitingPSOSVMSample2022,
  title = {Exploiting {{PSO-SVM}} and Sample Entropy in {{BEMD}} for the Prediction of Interval-Valued Time Series and Its Application to Daily {{PM2}}.5 Concentration Forecasting},
  author = {Jiang, Liyuan and Tao, Zhifu and Zhu, Jiaming and Zhang, Junting and Chen, Huayou},
  year = {2022},
  month = jul,
  journal = {Applied Intelligence},
  issn = {0924-669X, 1573-7497},
  doi = {10.1007/s10489-022-03835-3},
  urldate = {2023-03-05},
  abstract = {In view of the serious harm to human health caused by atmospheric fine particulate matter (PM2.5), accurate prediction of high concentrations of PM2.5 can help to provide timely warnings. On the other hand, due to the complexity of the formation and transmission process, it is difficult to accurately predict PM2.5. The aim of this paper is to develop a hybrid interval-valued time series prediction model, namely, BEMDCR-SE-PSO-SVM, by considering daily changes in pollutant concentrations and thereby realize interval-valued PM2.5 concentration prediction with high accuracy. The theoretical contributions in this paper include (1) the problem of edge effects corresponding to BEMD associated with interval-valued time-series is addressed by using the mirror extension method, and (2) the transformation between interval-valued time series and complex-valued signals is renewed from the perspective of centre/radius so that lower data fluctuations can be obtained. Technologically, sample entropy is introduced to provide an objective way to integrate decomposed similar IMFs so that subsequent prediction processes can be simplified. Finally, a numerical example is shown to illustrate the feasibility and validity of the developed hybrid interval-valued time series prediction model.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\3LADFI6T\Jiang ç­‰ - 2022 - Exploiting PSO-SVM and sample entropy in BEMD for .pdf}
}

@article{keyongwanNovelTimepowerBased2021,
  title = {A Novel Time-Power Based Grey Model for Nonlinear Time Series Forecasting},
  author = {{Keyong Wan} and {Bin Li} and {Weijie Zhou} and {Haicheng Zhu} and {Song Ding}},
  year = {2021},
  month = aug,
  journal = {Engineering Applications of Artificial Intelligence},
  doi = {10.1016/j.engappai.2021.104441},
  abstract = {{$<$}p{$>$}To deal with various nonlinear issues in real applications, a novel time-power based grey model is put forward. However, in the original form of this model, the time-power parameter {$<$}math{$><$}mi is="true"{$>\alpha<$}/mi{$><$}/math{$>$} normally equals to an integer, and then the analytical expression of the time response function will be obtained. Otherwise, if the parameter {$<$}math{$><$}mi is="true"{$>\alpha<$}/mi{$><$}/math{$>$} equals to a non-integer, one cannot obtain the concrete time response function for future estimations. This situation may significantly restrict the applications of this grey model. To address such drawbacks, an optimized version is designed in this work. In the proposed model, a simplified solution to the differential equation is derived by using the definite integral technique. Furthermore, for improving accuracy, the time-power parameter {$<$}math{$><$}mi is="true"{$>\alpha<$}/mi{$><$}/math{$>$} is optimized by utilizing the Particle Swarm Optimization algorithm based on the model parameter packages. Subsequently, the efficacy and practicality of this simplified function have been verified by numerical simulations and experimental studies. Moreover, the method of probability density prediction is employed for verifying the reliability and stability of the proposed model for the first time when predicting the settlement of the soft-clay subgrade on an expressway. The demonstration cases illustrate that the quantitative improvements over forecasts of the proposed model are even more pronounced with a level accuracy of 2.29\% and 1.19\% MAPE values in the fitted and predicted periods, respectively, which can significantly increase the predicting accuracy by more than 10\% with respect to the other benchmarks. Therefore, the new proposed model not only has greater~application~fields~and~prospects but also achieves higher and more reliable predicting accuracy with the optimal {$<$}math{$><$}mi is="true"{$>\alpha<$}/mi{$><$}/math{$>$} under the support of the Particle Swarm Optimization algorithm, compared with the competing models.{$<$}/p{$>$}},
  copyright = {6.6936},
  lccn = {7.8024},
  file = {C:\Users\Epictus\Zotero\storage\N6LJ7DUX\Keyong Wan et al_2021_A novel time-power based grey model for nonlinear time series forecasting.pdf}
}

@article{liEnhancingLocalityBreaking,
  title = {Enhancing the {{Locality}} and {{Breaking}} the {{Memory Bottleneck}} of {{Transformer}} on {{Time Series Forecasting}}},
  author = {Li, Shiyang and Jin, Xiaoyong and Xuan, Yao and Zhou, Xiyou and Chen, Wenhu and Wang, Yu-Xiang and Yan, Xifeng},
  abstract = {Time series forecasting is an important problem across many domains, including predictions of solar plant energy output, electricity consumption, and traffic jam situation. In this paper, we propose to tackle such forecasting problem with Transformer [1]. Although impressed by its performance in our preliminary study, we found its two major weaknesses: (1) locality-agnostics: the point-wise dotproduct self-attention in canonical Transformer architecture is insensitive to local context, which can make the model prone to anomalies in time series; (2) memory bottleneck: space complexity of canonical Transformer grows quadratically with sequence length L, making directly modeling long time series infeasible. In order to solve these two issues, we first propose convolutional self-attention by producing queries and keys with causal convolution so that local context can be better incorporated into attention mechanism. Then, we propose LogSparse Transformer with only O(L(log L)2) memory cost, improving forecasting accuracy for time series with fine granularity and strong long-term dependencies under constrained memory budget. Our experiments on both synthetic data and realworld datasets show that it compares favorably to the state-of-the-art.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\KFMNAT6U\Li ç­‰ - Enhancing the Locality and Breaking the Memory Bot.pdf}
}

@article{LinSongXianYuChuangYeHuoDongNongMinZengShouYuGongTongFuYuJiYuZhongGuoXianJiShuJuDeShiZhengYanJiu2023,
  title = {{å¿åŸŸåˆ›ä¸šæ´»åŠ¨ã€å†œæ°‘å¢æ”¶ä¸å…±åŒå¯Œè£•{\textemdash}{\textemdash}åŸºäºä¸­å›½å¿çº§æ•°æ®çš„å®è¯ç ”ç©¶}},
  author = {æ—åµ© and è°·æ‰¿åº” and æ–¯æ™“å¤« and ä¸¥é›¨å§—},
  year = {2023},
  journal = {ç»æµç ”ç©¶},
  volume = {58},
  number = {3},
  pages = {40--58},
  issn = {0577-9154},
  abstract = {å…±åŒå¯Œè£•æ˜¯ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰çš„æ ¹æœ¬åŸåˆ™ï¼Œæ˜¯å…¨ä½“äººæ°‘ä¸ºä¹‹å¥‹æ–—çš„ç›®æ ‡å’ŒçŸ¢å¿—ä¸æ¸çš„è¿½æ±‚ã€‚åœ¨æˆ‘å›½ï¼Œå†œæ‘äººå£å ä½æ”¶å…¥ç¾¤ä½“çš„æ¯”ä¾‹è¾ƒé«˜ï¼Œå¹¶ä¸”å†œæ°‘æ”¶å…¥æ™®éåä½ã€‚åœ¨æ­¤èƒŒæ™¯ä¸‹ï¼Œæå‡å†œæ°‘æ”¶å…¥æ˜¯å®ç°å…±åŒå¯Œè£•çš„åŸºç¡€æ¡ä»¶å’Œç‰©è´¨ä¿éšœã€‚æœ¬æ–‡åˆ©ç”¨2000{\textemdash}2017å¹´ä¸­å›½1749ä¸ªå¿çº§è¡Œæ”¿åŒºçš„æ•°æ®ï¼Œå¯¹å¿åŸŸåˆ›ä¸šæ´»åŠ¨ä¸å†œæ‘å±…æ°‘å¯æ”¯é…æ”¶å…¥çš„å…³ç³»è¿›è¡Œäº†å®è¯åˆ†æã€‚ç ”ç©¶å‘ç°ï¼Œé¦–å…ˆï¼Œå¿åŸŸåˆ›ä¸šæœ‰åˆ©äºå†œæ°‘å¢æ”¶ï¼Œç‰¹åˆ«è¡¨ç°ä¸ºå°å¾®å‹åŠå…¬å¸åˆ¶çš„åˆ›ä¸šæ´»åŠ¨ã€‚è¿›ä¸€æ­¥ç ”ç©¶å‘ç°ï¼Œå¿åŸŸåˆ›ä¸šæœ‰åˆ©äºç¼©å°åŸä¹¡æ”¶å…¥å·®è·ã€‚æ­¤å¤–ï¼Œæ”¿åºœè§„æ¨¡å¯¹åˆ›ä¸šçš„å‡è´«æ•ˆæœå…·æœ‰``å€’Uå‹''çš„è°ƒèŠ‚ä½œç”¨ï¼Œè¿™ä¸€ä½œç”¨ä¸»è¦ä½“ç°åœ¨ä¸­è¥¿éƒ¨åœ°åŒºã€‚æœ¬æ–‡é€šè¿‡è¿›ä¸€æ­¥åˆ†æå¿åŸŸä¹‹é—´åœ¨åŸºç¡€è®¾æ–½å»ºè®¾å’Œæ•°å­—ç»æµå»ºè®¾æ–¹é¢çš„ç‰¹å¾å·®å¼‚ï¼Œå‘ç°åœ¨æœªå¼€é€šé«˜é“çš„å¿åŸŸå’Œéç”µå­å•†åŠ¡ç¤ºèŒƒå¿åŸŸï¼Œå¿åŸŸåˆ›ä¸šä¸æ”¿åºœè§„æ¨¡çš„å…±åŒä½œç”¨æ›´åŠ æ˜æ˜¾ã€‚æœ€åï¼Œæœ¬æ–‡ç»“åˆæ¡ˆä¾‹åˆ†æï¼Œè¿›ä¸€æ­¥æ¢ç´¢äº†ç‰¹å®šåŒºåŸŸçš„ç‰¹è‰²åŒ–åˆ›ä¸šå¢æ”¶é“è·¯ï¼Œä¸ºæå‡å†œæ°‘æ”¶å…¥æä¾›äº†å¯è¡Œè·¯å¾„ã€‚},
  langid = {chinese},
  file = {C:\Users\Epictus\Zotero\storage\CNK9IQWU\å¿åŸŸåˆ›ä¸šæ´»åŠ¨ã€å†œæ°‘å¢æ”¶ä¸å…±...åŸºäºä¸­å›½å¿çº§æ•°æ®çš„å®è¯ç ”ç©¶_æ—åµ©.pdf}
}

@article{liPENPredictionExplanationNetwork2023,
  title = {{{PEN}}: {{Prediction-Explanation Network}} to {{Forecast Stock Price Movement}} with {{Better Explainability}}},
  shorttitle = {{{PEN}}},
  author = {Li, Shuqi and Liao, Weiheng and Chen, Yuhan and Yan, Rui},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {4},
  pages = {5187--5194},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v37i4.25648},
  urldate = {2023-07-05},
  abstract = {Nowadays explainability in stock price movement prediction is attracting increasing attention in banks, hedge funds and asset managers, primarily due to audit or regulatory reasons. Text data such as financial news and social media posts can be part of the reasons for stock price movement. To this end, we propose a novel framework of Prediction-Explanation Network (PEN) jointly modeling text streams and price streams with alignment. The key component of the PEN model is an shared representation learning module that learns which texts are possibly associated with the stock price movement by modeling the interaction between the text data and stock price data with a salient vector characterizing their correlation. In this way, the PEN model is able to predict the stock price movement by identifying and utilizing abundant messages while on the other hand, the selected text messages also explain the stock price movement. Experiments on real-world datasets demonstrate that we are able to kill two birds with one stone: in terms of accuracy, the proposed PEN model outperforms the state-of-art baseline; on explainability, the PEN model are demonstrated to be far superior to attention mechanism, capable of picking out the crucial texts with a very high confidence.},
  langid = {english},
  annotation = {titleTranslation:},
  file = {C:\Users\Epictus\Zotero\storage\XEK7JU5R\Li ç­‰ - 2023 - PEN Prediction-Explanation Network to Forecast St.pdf}
}

@misc{liuITransformerInvertedTransformers2023,
  title = {{{iTransformer}}: {{Inverted Transformers Are Effective}} for {{Time Series Forecasting}}},
  shorttitle = {{{iTransformer}}},
  author = {Liu, Yong and Hu, Tengge and Zhang, Haoran and Wu, Haixu and Wang, Shiyu and Ma, Lintao and Long, Mingsheng},
  year = {2023},
  month = oct,
  number = {arXiv:2310.06625},
  eprint = {2310.06625},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-10-26},
  abstract = {The recent boom of linear forecasting models questions the ongoing passion for architectural modifications of Transformer-based forecasters. These forecasters leverage Transformers to model the global dependencies over temporal tokens of time series, with each token formed by multiple variates of the same timestamp. However, Transformer is challenged in forecasting series with larger lookback windows due to performance degradation and computation explosion. Besides, the unified embedding for each temporal token fuses multiple variates with potentially unaligned timestamps and distinct physical measurements, which may fail in learning variate-centric representations and result in meaningless attention maps. In this work, we reflect on the competent duties of Transformer components and repurpose the Transformer architecture without any adaptation on the basic components. We propose iTransformer that simply inverts the duties of the attention mechanism and the feed-forward network. Specifically, the time points of individual series are embedded into variate tokens which are utilized by the attention mechanism to capture multivariate correlations; meanwhile, the feed-forward network is applied for each variate token to learn nonlinear representations. The iTransformer model achieves consistent state-of-the-art on several real-world datasets, which further empowers the Transformer family with promoted performance, generalization ability across different variates, and better utilization of arbitrary lookback windows, making it a nice alternative as the fundamental backbone of time series forecasting.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {C:\Users\Epictus\Zotero\storage\B8QXQ45A\Liu ç­‰ - 2023 - iTransformer Inverted Transformers Are Effective .pdf}
}

@article{liuPYRAFORMERLOWCOMPLEXITYPYRAMIDAL2022,
  title = {{{PYRAFORMER}}: {{LOW-COMPLEXITY PYRAMIDAL AT- TENTION FOR LONG-RANGE TIME SERIES MODELING AND FORECASTING}}},
  author = {Liu, Shizhan and Yu, Hang and Liao, Cong and Li, Jianguo and Lin, Weiyao and Liu, Alex X and Dustdar, Schahram},
  year = {2022},
  abstract = {Accurate prediction of the future given the past based on time series data is of paramount importance, since it opens the door for decision making and risk management ahead of time. In practice, the challenge is to build a flexible but parsimonious model that can capture a wide range of temporal dependencies. In this paper, we propose Pyraformer by exploring the multi-resolution representation of the time series. Specifically, we introduce the pyramidal attention module (PAM) in which the inter-scale tree structure summarizes features at different resolutions and the intra-scale neighboring connections model the temporal dependencies of different ranges. Under mild conditions, the maximum length of the signal traversing path in Pyraformer is a constant (i.e., O(1)) with regard to the sequence length L, while its time and space complexity scale linearly with L. Extensive experimental results show that Pyraformer typically achieves the highest prediction accuracy in both single-step and long-range multi-step forecasting tasks with the least amount of time and memory consumption, especially when the sequence is long1.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\W3ERTZZF\Liu ç­‰ - 2022 - PYRAFORMER LOW-COMPLEXITY PYRAMIDAL AT- TENTION F.pdf}
}

@article{lvAdaptiveMultivariateTimeSeries2023,
  title = {Adaptive {{Multivariate Time-Series Anomaly Detection}}},
  author = {Lv, Jianming and Wang, Yaquan and Chen, Shengjing},
  year = {2023},
  month = jul,
  journal = {Information Processing \& Management},
  volume = {60},
  number = {4},
  pages = {103383},
  issn = {03064573},
  doi = {10.1016/j.ipm.2023.103383},
  urldate = {2023-05-20},
  abstract = {Existing Multivariate time-series anomaly detection methods aim to calculate the anomaly scores of observed sequences and learn a threshold to judge whether the input data is abnormal. However, they neglected the temporal covariate shift problem, which leads to the learned thresholds cannot be generalized in the test set, resulting in suboptimal detection performance in practical cases. We propose the Adaptive Multivariate Time-series Anomaly Detection framework in this paper, namely DATECT, to address the above challenging problems. Specifically, to enhance the robustness of anomaly measurement, DATECT adopts the dilated convolution based AutoEncoder to integrate both prediction errors and reconstruction errors into the output anomaly scores. Meanwhile, a novel Adaptive Window Normalization method is put forth to reduce the diversity of the distribution of anomaly scores in the test set, hence effectively improving the generalization capability of the detection model. Finally, to further reduce the side-effect of domain-specific dynamic noise, DATECT utilizes Non-parametric Scan Statistics to select the subsets of significantly abnormal signals and highlight the anomaly segments. Experiments on five datasets show that our method can significantly alleviate the performance drop caused by the temporal covariate shift problem, outperforms the baseline in terms of detection performance and generalization, averagely improving the F1-score by 8.66\% and the F1{${_\ast}$}-score (upper bound) by 1.18\%.},
  copyright = {7.036},
  langid = {english},
  lccn = {7.466},
  file = {C:\Users\Epictus\Zotero\storage\ACC34EZU\Lv ç­‰ - 2023 - Adaptive Multivariate Time-Series Anomaly Detectio.pdf}
}

@article{martinFoodTradePolicy,
  title = {Food {{Trade Policy}} and {{Food Price Volatility}}},
  author = {Martin, Will and Mamun, Abdullah and Minot, Nicholas},
  abstract = {Food trade barriers in many countries are systematically adjusted using measures such as export restrictions and tariff changes to insulate domestic markets from world price changes{\textemdash}a response not predicted by traditional political economy models. In this study, policy makers minimize costs from changing domestic prices, and of deviating from longer-run political-economy equilibria. Error correction techniques are applied to non-stationary domestic and world price data for rice and wheat collected to measure trade policy distortions. The results suggest that systematic shortrun price insulation reduces shocks to domestic prices but roughly doubles the amplitude of shocks to world prices. Random policy shocks from current policies increase domestic price volatility relative to the magnified volatility of world prices. National policy reforms to move away from discretionary, destabilizing policies could lower costs, reduce volatility in domestic and world prices and facilitate reform of international trade rules.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\PD2WDXBH\Martin ç­‰ - Food Trade Policy and Food Price Volatility.pdf}
}

@article{nieEMDSVRModelShortterm2020,
  title = {An {{EMD-SVR}} Model for Short-Term Prediction of Ship Motion Using Mirror Symmetry and {{SVR}} Algorithms to Eliminate {{EMD}} Boundary Effect},
  author = {Nie, Zhihong and Shen, Feng and Xu, Dingjie and Li, Qinhua},
  year = {2020},
  month = dec,
  journal = {Ocean Engineering},
  volume = {217},
  pages = {107927},
  issn = {00298018},
  doi = {10.1016/j.oceaneng.2020.107927},
  urldate = {2023-02-19},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\YFEF58G5\Nie ç­‰ - 2020 - An EMD-SVR model for short-term prediction of ship.pdf}
}

@article{panIsingTrafficUsingIsing2023,
  title = {Ising-{{Traffic}}: {{Using Ising Machine Learning}} to {{Predict Traffic Congestion}} under {{Uncertainty}}},
  shorttitle = {Ising-{{Traffic}}},
  author = {Pan, Zhenyu and Sharma, Anshujit and Hu, Jerry Yao-Chieh and Liu, Zhuo and Li, Ang and Liu, Han and Huang, Michael and Geng, Tony},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {8},
  pages = {9354--9363},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v37i8.26121},
  urldate = {2023-07-02},
  abstract = {This paper addresses the challenges in accurate and real-time traffic congestion prediction under uncertainty by proposing Ising-Traffic, a dual-model Ising-model-based traffic prediction framework that delivers higher accuracy and lower latency than SOTA solutions. While traditional solutions face the dilemma from the trade-off between algorithm complexity and computational efficiency, our Ising-model-based method breaks away from the trade-off leveraging the Ising model's strong expressivity and the Ising machine's strong computation power. In particular, Ising-Traffic formulates traffic prediction under uncertainty into two Ising models: Reconstruct-Ising and Predict-Ising. Reconstruct-Ising is mapped onto modern Ising machines and handles uncertainty in traffic accurately with negligible latency and energy consumption, while Predict-Ising is mapped onto traditional processors and predicts future congestion precisely with only at most 1.8\% computational demands of existing solutions. Our evaluation shows Ising-Traffic delivers on average 98{\texttimes} speedups and 5\% accuracy improvement over SOTA.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\US43QFVH\Pan ç­‰ - 2023 - Ising-Traffic Using Ising Machine Learning to Pre.pdf}
}

@article{pressmanEconomicContributionsAmartya2000,
  title = {The {{Economic Contributions}} of {{Amartya Sen}}},
  author = {Pressman, Steven and Summerfield, Gale},
  year = {2000},
  month = jan,
  journal = {Review of Political Economy},
  volume = {12},
  number = {1},
  pages = {89--113},
  issn = {0953-8259, 1465-3982},
  doi = {10.1080/095382500106830},
  urldate = {2023-03-04},
  langid = {english},
  file = {C\:\\Users\\Epictus\\Zotero\\storage\\9Z5UZNE2\\Pressman å’Œ Summerfield - 2000 - The Economic Contributions of Amartya Sen.pdf;C\:\\Users\\Epictus\\Zotero\\storage\\WTWLZCBC\\Pressman_Summerfield_2000_The Economic Contributions of Amartya Sen.pdf}
}

@inproceedings{shiUnderwaterTerrainMeasurement2023,
  title = {Underwater {{Terrain Measurement Based}} on {{Unmanned Measurement Ship Multi-Beam Bathymeter}}},
  booktitle = {2023 5th {{International Conference}} on {{Intelligent Control}}, {{Measurement}} and {{Signal Processing}} ({{ICMSP}})},
  author = {Shi, Xiaoping},
  year = {2023},
  month = may,
  pages = {706--709},
  publisher = {{IEEE}},
  address = {{Chengdu, China}},
  doi = {10.1109/ICMSP58539.2023.10170977},
  urldate = {2023-10-14},
  abstract = {Underwater topographic survey is the surveying and mapping work to measure the plane position and elevation of rivers, lakes, oceans, channels and harbors, and draw underwater topographic maps. With the development of China's economy, progress in technology, and acceleration of infrastructure construction, the combination of GNSS RTK and multi beam bathymetry by unmanned surveying ships has improved the problems of personnel safety and low measurement accuracy in traditional underwater terrain surveying methods. This article introduces the principle and method of multi beam bathymetry, as well as the GNSS-RTK three-dimensional bathymetry technology. Combined with engineering examples, it analyzes the integrated RTK three-dimensional bathymetry system of unmanned measurement ship multi beam bathymetry system, providing a new method and idea for underwater terrain measurement.},
  isbn = {9798350336030},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\HHKFE4GS\Shi - 2023 - Underwater Terrain Measurement Based on Unmanned M.pdf}
}

@article{songdingEntropybasedTOPSISOptimized2022,
  title = {An Entropy-Based {{TOPSIS}} and Optimized Grey Prediction Model for Spatiotemporal Analysis in Strategic Emerging Industry},
  author = {{Song Ding} and {Ruojin Li} and {Junha Guo}},
  year = {2022},
  month = nov,
  journal = {Expert Systems with Applications},
  doi = {10.1016/j.eswa.2022.119169},
  abstract = {{$<$}p{$>$}Stepping into the stage of high-quality and innovation-driven development, the 14th Five-Year Plan for China places a high priority on advancing the strategic emerging industry (SEI). An integrated strategic emerging industry-economy-environment ({$<$}em{$>$}IEE{$<$}/em{$>$}) system is constructed to investigate the sustainability of {$<$}em{$>$}SE{$<$}/em{$>$}I. The development quality of the three subsystems is assessed by the entropy-based {$<$}em{$>$}TOPSIS{$<$}/em{$>$}. Furthermore, the evolution trend, spatial distribution, and the prospects of the coupling coordination degree ({$<$}em{$>$}CCD{$<$}/em{$>$}) for the {$<$}em{$>$}IEE{$<$}/em{$>$} system are researched. Findings indicate that the respective evolution trend of {$<$}em{$>$}CCD{$<$}/em{$>$} exhibits an N-shape pattern from 2011 to 2019 in the 11 districts of the Yangtze River Economic Belt. Moreover, mutual promotion and interaction exist between the strategic emerging industrial system and the economic system reflected by analogous evolution patterns. The spatial distribution for {$<$}em{$>$}CCD{$<$}/em{$>$} is featured with a stepwise decline among these 11 districts from lower to upper reaches of the Yangtze River, mostly attributed to the lagged industrial and economic growth in the districts of upper and middle reaches. As predicted by the improved grey Bernoulli model, the prospect for {$<$}em{$>$}CCD{$<$}/em{$>$} generally will experience an upward trend. Based on the empirical results, countermeasures are suggested to promote the sustainability and unleash the potential of {$<$}em{$>$}SEI{$<$}/em{$>$} for advancing high-quality development.{$<$}/p{$>$}}
}

@article{songGrowingChina2011,
  title = {Growing {{Like China}}},
  author = {Song, Zheng and Storesletten, Kjetil and Zilibotti, Fabrizio},
  year = {2011},
  month = feb,
  journal = {American Economic Review},
  volume = {101},
  number = {1},
  pages = {196--233},
  issn = {0002-8282},
  doi = {10.1257/aer.101.1.196},
  urldate = {2023-05-23},
  abstract = {We construct a growth model consistent with China's economic transition: high output growth, sustained returns on capital, reallocation within the manufacturing sector, and a large trade surplus. Entrepreneurial firms use more productive technologies, but due to financial imperfections they must finance investments through internal savings. State-owned firms have low productivity but survive because of better access to credit markets. High-productivity firms outgrow low-productivity firms if entrepreneurs have sufficiently high savings. The downsizing of financially integrated firms forces domestic savings to be invested abroad, generating a foreign surplus. A calibrated version of the theory accounts quantitatively for China's economic transition. (JEL E21, E22, E23, F43, L60, O16, O53, P23, P24, P31).},
  copyright = {11.6677},
  langid = {english},
  lccn = {11.4896},
  file = {C:\Users\Epictus\Zotero\storage\CUGPNZ89\Song ç­‰ - 2011 - Growing Like China.pdf}
}

@article{tangWindPowerForecasting2023,
  title = {Wind Power Forecasting: {{A}} Hybrid Forecasting Model and Multi-Task Learning-Based Framework},
  shorttitle = {Wind Power Forecasting},
  author = {Tang, Yugui and Yang, Kuo and Zhang, Shujing and Zhang, Zhen},
  year = {2023},
  month = sep,
  journal = {Energy},
  volume = {278},
  pages = {127864},
  issn = {03605442},
  doi = {10.1016/j.energy.2023.127864},
  urldate = {2023-05-27},
  abstract = {Accurate forecasting of wind power is of significance for scheduling the grid system when wind power is inte\- grated. However, the deficiency of the training data restricts the models' forecasting performance and modeling efficiency. In this study, we propose a hybrid forecasting model that is composed of a dual dilated convolutionbased self-attention sub-model and an autoregressive sub-model. The dual-branch sub-model utilizes a dual convolution architecture to extract both global and local temporal patterns before capturing attention-based dependencies between multivariate inputs to reflect non-linear correlations. The autoregressive sub-model learns linear correlations to provide supplementary information that compensates for the insensitivity of model response. Furthermore, a multi-task learning-based framework is designed to address insufficient training data of a new turbine cluster. The framework can be divided into one task-shared linear component and multiple task-specific non-linear components. By weighting multiple forecasting tasks, the proposed framework utilizes the collaborative relationships between tasks to improve accuracy on the target turbines. Experiment results show that the proposed forecasting model presents the better forecasting accuracy on actual datasets, and the framework has a significant improvement of 20.08\% in accuracy while further reducing dependence on training data, especially for source domain data in transfer learning.},
  copyright = {8.2338},
  langid = {english},
  lccn = {8.8569},
  file = {C:\Users\Epictus\Zotero\storage\5TCHGYCQ\Tang ç­‰ - 2023 - Wind power forecasting A hybrid forecasting model.pdf}
}

@article{truongSelectiveReviewOffline2020,
  title = {Selective Review of Offline Change Point Detection Methods},
  author = {Truong, Charles and Oudre, Laurent and Vayatis, Nicolas},
  year = {2020},
  month = feb,
  journal = {Signal Processing},
  volume = {167},
  eprint = {1801.00718},
  primaryclass = {cs, stat},
  pages = {107299},
  issn = {01651684},
  doi = {10.1016/j.sigpro.2019.107299},
  urldate = {2023-11-20},
  abstract = {This article presents a selective survey of algorithms for the offline detection of multiple change points in multivariate time series. A general yet structuring methodological strategy is adopted to organize this vast body of work. More precisely, detection algorithms considered in this review are characterized by three elements: a cost function, a search method and a constraint on the number of changes. Each of those elements is described, reviewed and discussed separately. Implementations of the main algorithms described in this article are provided within a Python package called ruptures.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {{Computer Science - Computational Engineering, Finance, and Science},Statistics - Computation,Statistics - Methodology},
  file = {C:\Users\Epictus\Zotero\storage\3DFBCVAR\Truong ç­‰ - 2020 - Selective review of offline change point detection.pdf}
}

@article{ullmannMultivariateTimeSeries2023,
  title = {Multivariate {{Time Series Information Bottleneck}}},
  author = {Ullmann, Denis and Taran, Olga and Voloshynovskiy, Slava},
  year = {2023},
  month = may,
  journal = {Entropy},
  volume = {25},
  number = {5},
  pages = {831},
  issn = {1099-4300},
  doi = {10.3390/e25050831},
  urldate = {2023-05-25},
  abstract = {Time series (TS) and multiple time series (MTS) predictions have historically paved the way for distinct families of deep learning models. The temporal dimension, distinguished by its evolutionary sequential aspect, is usually modeled by decomposition into the trio of ``trend, seasonality, noise'', by attempts to copy the functioning of human synapses, and more recently, by transformer models with self-attention on the temporal dimension. These models may find applications in finance and e-commerce, where any increase in performance of less than 1\% has large monetary repercussions, they also have potential applications in natural language processing (NLP), medicine, and physics. To the best of our knowledge, the information bottleneck (IB) framework has not received significant attention in the context of TS or MTS analyses. One can demonstrate that a compression of the temporal dimension is key in the context of MTS. We propose a new approach with partial convolution, where a time sequence is encoded into a two-dimensional representation resembling images. Accordingly, we use the recent advances made in image extension to predict an unseen part of an image from a given one. We show that our model compares well with traditional TS models, has information{\textendash}theoretical foundations, and can be easily extended to more dimensions than only time and space. An evaluation of our multiple time series{\textendash}information bottleneck (MTS-IB) model proves its efficiency in electricity production, road traffic, and astronomical data representing solar activity, as recorded by NASA's interface region imaging spectrograph (IRIS) satellite.},
  copyright = {2.6418},
  langid = {english},
  lccn = {2.7381},
  file = {C:\Users\Epictus\Zotero\storage\6UQXS5ED\Ullmann ç­‰ - 2023 - Multivariate Time Series Information Bottleneck.pdf}
}

@article{vaswaniAttentionAllYou,
  title = {Attention Is {{All}} You {{Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\WM89DQA8\Vaswani ç­‰ - Attention is All you Need.pdf}
}

@article{wangEnsembleForecastingSystem2023,
  title = {Ensemble Forecasting System Based on Decomposition-Selection-Optimization for Point and Interval Carbon Price Prediction},
  author = {Wang, Jianzhou and Wang, Ying and Li, Hongmin and Yang, Hufang and Li, Zhiwu},
  year = {2023},
  month = jan,
  journal = {Applied Mathematical Modelling},
  volume = {113},
  pages = {262--286},
  issn = {0307904X},
  doi = {10.1016/j.apm.2022.09.004},
  urldate = {2023-02-22},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\LW28JQAE\Wang ç­‰ - 2023 - Ensemble forecasting system based on decomposition.pdf}
}

@article{wangImprovingForecastingAccuracy2023,
  title = {Improving the Forecasting Accuracy of Interval-Valued Carbon Price from a Novel Multi-Scale Framework with Outliers Detection: {{An}} Improved Interval-Valued Time Series Analysis Mode},
  shorttitle = {Improving the Forecasting Accuracy of Interval-Valued Carbon Price from a Novel Multi-Scale Framework with Outliers Detection},
  author = {Wang, Piao and Tao, Zhifu and Liu, Jinpei and Chen, Huayou},
  year = {2023},
  month = feb,
  journal = {Energy Economics},
  volume = {118},
  pages = {106502},
  issn = {01409883},
  doi = {10.1016/j.eneco.2022.106502},
  urldate = {2023-02-22},
  abstract = {Accurate carbon price forecasting can provide policymakers with a reasonable basis for carbon pricing. Intervalvalued carbon price forecasting could provide sufficient information compared with real-valued carbon price time series prediction. On the other hand, current interval-valued carbon price forecasting has major challenges including data complexity, outliers, and the selection of forecasting methods, which make the forecasting results with great uncertainty and instability. To address these issues, this paper proposes an interval-valued carbon price forecasting method based on new data processing techniques, and discusses the effects of different com\- binations of interval variables on the forecasting results. We first established interval complete ensemble empirical mode decomposition with adaptive noise (ICEEMDAN) and interval outlier detection method (Iksigma) to reduce the data complexity and identify outliers. Then, various neural network models include in\- terval multilayer perceptron (IMLP), multi-output support vector regression (MSVR), long short-term memory network (LSTM), gated recurrent unit neural network (GRU), and convolution neural network (CNN) are chosen to conduct combination forecasting on the interval sub-modes produced by ICEEMDAN. The final results are obtained by summing the interval sub-modes. Finally, taking the carbon trading price in Hubei as the research object, the results show that the developed forecasting framework is superior to all comparison models in forecasting precision and stability. Furthermore, different combinations of interval variables (CRM, Minmax, L + 2R, and U-2R) lead to different decomposition results and outlier detection results, which finally affect the prediction results.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\Z3LDHC8V\Wang ç­‰ - 2023 - Improving the forecasting accuracy of interval-val.pdf}
}

@article{wangMICNMULTISCALELOCAL2023,
  title = {{{MICN}}: {{MULTI-SCALE LOCAL AND GLOBAL CONTEXT MODELING FOR LONG-TERM SERIES FORECASTING}}},
  author = {Wang, Huiqiang and Peng, Jian and Huang, Feihu and Wang, Jince and Chen, Junhui and Xiao, Yifei},
  year = {2023},
  abstract = {Recently, Transformer-based methods have achieved surprising performance in the field of long-term series forecasting, but the attention mechanism for computing global correlations entails high complexity. And they do not allow for targeted modeling of local features as CNN structures do. To solve the above problems, we propose to combine local features and global correlations to capture the overall view of time series (e.g., fluctuations, trends). To fully exploit the underlying information in the time series, a multi-scale branch structure is adopted to model different potential patterns separately. Each pattern is extracted with down-sampled convolution and isometric convolution for local features and global correlations, respectively. In addition to being more effective, our proposed method, termed as Multi-scale Isometric Convolution Network (MICN), is more efficient with linear complexity about the sequence length with suitable convolution kernels. Our experiments on six benchmark datasets show that compared with state-of-the-art methods, MICN yields 17.2\% and 21.6\% relative improvements for multivariate and univariate time series, respectively. Code is available at https://github. com/wanghq21/MICN.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\BGZJPALX\Wang ç­‰ - 2023 - MICN MULTI-SCALE LOCAL AND GLOBAL CONTEXT MODELIN.pdf}
}

@article{wangNovelFrameworkCarbon2022,
  title = {A Novel Framework for Carbon Price Forecasting with Uncertainties},
  author = {Wang, Minggang and Zhu, Mengrui and Tian, Lixin},
  year = {2022},
  month = aug,
  journal = {Energy Economics},
  volume = {112},
  pages = {106162},
  issn = {01409883},
  doi = {10.1016/j.eneco.2022.106162},
  urldate = {2023-02-22},
  abstract = {Carbon price prediction is a key issue in the field of carbon market research. However, the existing methods of carbon price forecasting mostly regard carbon price series as a certain time series, but pay less attention to the uncertainty implied by carbon price series. Based on this, this paper proposes a forecasting model framework considering the uncertainty of carbon price series, which represents the carbon price series as a time series of probability density function to deal with the uncertainty. A prediction model based on the probability density recurrence network of carbon price is constructed with the help of the recurrence network construction tech\- nology of data and link prediction, and the advantages of the model are verified by numerical simulation. The empirical analysis is made by using the EU carbon price data. In the whole sample interval, we build 123 time windows. The results indicate that our prediction model has better level forecasting precision in 90.69\% time windows and directional prediction accuracy in 67.82\% time windows than the prediction model built based on deterministic network, which can improve the level prediction accuracy and directional prediction accuracy by 25.76\% and 5.09\% on average. By comparing with the accuracy results of existing carbon price prediction models, we discuss the feasibility of improving the prediction effect by increasing the number of similar nodes.},
  copyright = {9.489},
  langid = {english},
  lccn = {9.252},
  keywords = {probability density distribution function,uncertainties},
  file = {C:\Users\Epictus\Zotero\storage\664ISMXI\Wang ç­‰ - 2022 - A novel framework for carbon price forecasting wit.pdf}
}

@misc{wangOutofdistributionDetectionImplicit2023,
  title = {Out-of-Distribution {{Detection}} with {{Implicit Outlier Transformation}}},
  author = {Wang, Qizhou and Ye, Junjie and Liu, Feng and Dai, Quanyu and Kalander, Marcus and Liu, Tongliang and Hao, Jianye and Han, Bo},
  year = {2023},
  month = mar,
  number = {arXiv:2303.05033},
  eprint = {2303.05033},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-03-10},
  abstract = {Outlier exposure (OE) is powerful in out-of-distribution (OOD) detection, enhancing detection capability via model fine-tuning with surrogate OOD data. However, surrogate data typically deviate from test OOD data. Thus, the performance of OE, when facing unseen OOD data, can be weakened. To address this issue, we propose a novel OE-based approach that makes the model perform well for unseen OOD situations, even for unseen OOD cases. It leads to a min-max learning scheme -- searching to synthesize OOD data that leads to worst judgments and learning from such OOD data for uniform performance in OOD detection. In our realization, these worst OOD data are synthesized by transforming original surrogate ones. Specifically, the associated transform functions are learned implicitly based on our novel insight that model perturbation leads to data transformation. Our methodology offers an efficient way of synthesizing OOD data, which can further benefit the detection model, besides the surrogate OOD data. We conduct extensive experiments under various OOD detection setups, demonstrating the effectiveness of our method against its advanced counterparts.},
  archiveprefix = {arxiv},
  file = {C\:\\Users\\Epictus\\Zotero\\storage\\TZGZJ2CZ\\Wang et al_2023_Out-of-distribution Detection with Implicit Outlier Transformation.pdf;C\:\\Users\\Epictus\\Zotero\\storage\\DMA6IWLZ\\2303.html}
}

@article{weijiezhouNovelGreyPrediction2021,
  title = {A Novel Grey Prediction Model for Seasonal Time Series},
  author = {{Weijie Zhou} and {Rongrong Jiang} and {Song Ding} and {Yuke Cheng} and {Yao Li} and {Huihui Tao}},
  year = {2021},
  month = aug,
  journal = {Knowledge-Based Systems},
  doi = {10.1016/j.knosys.2021.107363},
  abstract = {{$<$}p{$>$}Considering the weakness in the discrete grey seasonal model, a new grey seasonal model is put forward by introducing a time trends item. Moreover, some properties of this proposed model are deduced, such as the unbiased feature, to provide more information to perceive this model. Subsequently, four time series concerning the quarterly and monthly electricity and petroleum consumptions that have various features of the upward, downward, and wave tendencies from China, America, Japan, and Germany, are adopted to verify the availability and generality of this new model. Experimental results from these four case studies demonstrate that, on the one hand, the proposed method can strikingly improve the simulating and forecasting performance compared with the conventional discrete grey seasonal model, indicating this new model is capable of describing seasonal time series with different tendencies. On the other hand, this new technology is validated to have superior forecasting ability over a range of grey models, econometric models, and machine learning methods. Finally, the impact of sample size on the precision for the new model is further discussed, and results suggest that the modeling sample length should be at least four times the number of cycles in a seasonal sequence in order to ensure the satisfied and stable forecasting accuracy.{$<$}/p{$>$}},
  copyright = {8.1534},
  lccn = {8.1388},
  file = {C:\Users\Epictus\Zotero\storage\S8QTUHPL\Weijie Zhou et al_2021_A novel grey prediction model for seasonal time series.pdf}
}

@article{weissSurveyTransferLearning2016,
  title = {A Survey of Transfer Learning},
  author = {Weiss, Karl and Khoshgoftaar, Taghi M. and Wang, DingDing},
  year = {2016},
  month = dec,
  journal = {Journal of Big Data},
  volume = {3},
  number = {1},
  pages = {9},
  issn = {2196-1115},
  doi = {10.1186/s40537-016-0043-6},
  urldate = {2023-05-29},
  abstract = {Machine learning and data mining techniques have been used in numerous real-world applications. An assumption of traditional machine learning methodologies is the training data and testing data are taken from the same domain, such that the input feature space and data distribution characteristics are the same. However, in some real-world machine learning scenarios, this assumption does not hold. There are cases where training data is expensive or difficult to collect. Therefore, there is a need to create high-performance learners trained with more easily obtained data from different domains. This methodology is referred to as transfer learning. This survey paper formally defines transfer learning, presents information on current solutions, and reviews applications applied to transfer learning. Lastly, there is information listed on software downloads for various transfer learning solutions and a discussion of possible future research work. The transfer learning solutions surveyed are independent of data size and can be applied to big data environments.},
  copyright = {10.3346},
  langid = {english},
  file = {C\:\\Users\\Epictus\\Zotero\\storage\\QLEG9ZKP\\Weiss et al_2016_A survey of transfer learning.pdf;C\:\\Users\\Epictus\\Zotero\\storage\\TYTYUC88\\Weiss ç­‰ - 2016 - A survey of transfer learning.pdf}
}

@article{wolosiukDonPredictCounterfactual2023,
  title = {Don't {{Predict Counterfactual Values}}, {{Predict Expected Values Instead}}},
  author = {Wo{\l}osiuk, Jeremiasz and {\'S}wiechowski, Maciej and Ma{\'n}dziuk, Jacek},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {4},
  pages = {5303--5311},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v37i4.25661},
  urldate = {2023-07-02},
  abstract = {Counterfactual Regret Minimization algorithms are the most popular way of estimating the Nash Equilibrium in imperfectinformation zero-sum games. In particular, DeepStack - the state-of-the-art Poker bot {\textendash} employs the so-called Deep Counterfactual Value Network (DCVN) to learn the Counterfactual Values (CFVs) associated with various states in the game. Each CFV is a multiplication of two factors: (1) the probability that the opponent would reach a given state in a game, which can be explicitly calculated from the input data, and (2) the expected value (EV) of a payoff in that state, which is a complex function of the input data, hard to calculate. In this paper, we propose a simple yet powerful modification to the CFVs estimation process, which consists in utilizing a deep neural network to estimate only the EV factor of CFV. This new target setting significantly simplifies the learning problem and leads to much more accurate CFVs estimation. A direct comparison, in terms of CFVs prediction losses, shows a significant prediction accuracy improvement of the proposed approach (DEVN) over the original DCVN formulation (relatively by 9.18 - 15.70\% when using card abstraction, and by 3.37 - 8.39\% without card abstraction, depending on a particular setting). Furthermore, the application of DEVN improves the theoretical lower bound of the error by 29.05 - 31.83\% compared to the DCVN pipeline when card abstraction is applied.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\PJUDMW4B\WoÅ‚osiuk ç­‰ - 2023 - Donâ€™t Predict Counterfactual Values, Predict Expec.pdf}
}

@inproceedings{wuAutoformerDecompositionTransformers2021,
  title = {Autoformer: {{Decomposition Transformers}} with {{Auto-Correlation}} for {{Long-Term Series Forecasting}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Wu, Haixu and Xu, Jiehui and Wang, Jianmin and Long, Mingsheng},
  editor = {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P. S. and Vaughan, J. Wortman},
  year = {2021},
  volume = {34},
  pages = {22419--22430},
  publisher = {{Curran Associates, Inc.}},
  file = {C:\Users\Epictus\Zotero\storage\VU7RWSN2\Wu et al_2021_Autoformer.pdf}
}

@article{wuInterpretableWeatherForecasting2023,
  title = {Interpretable Weather Forecasting for Worldwide Stations with a Unified Deep Model},
  author = {Wu, Haixu and Zhou, Hang and Long, Mingsheng and Wang, Jianmin},
  year = {2023},
  month = jun,
  journal = {Nature Machine Intelligence},
  volume = {5},
  number = {6},
  pages = {602--611},
  issn = {2522-5839},
  doi = {10.1038/s42256-023-00667-9},
  urldate = {2023-07-05},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\FAPKVKGX\Wu ç­‰ - 2023 - Interpretable weather forecasting for worldwide st.pdf}
}

@misc{xueMakeTransformerGreat2023,
  title = {Make {{Transformer Great Again}} for {{Time Series Forecasting}}: {{Channel Aligned Robust Dual Transformer}}},
  shorttitle = {Make {{Transformer Great Again}} for {{Time Series Forecasting}}},
  author = {Xue, Wang and Zhou, Tian and Wen, Qingsong and Gao, Jinyang and Ding, Bolin and Jin, Rong},
  year = {2023},
  month = may,
  number = {arXiv:2305.12095},
  eprint = {2305.12095},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-05-27},
  abstract = {Recent studies have demonstrated the great power of deep learning methods, particularly Transformer and MLP, for time series forecasting. Despite its success in NLP and CV, many studies found that Transformer is less effective than MLP for time series forecasting. In this work, we design a special Transformer, i.e., channel-aligned robust dual Transformer (CARD for short), that addresses key shortcomings of Transformer in time series forecasting. First, CARD introduces a dual Transformer structure that allows it to capture both temporal correlations among signals and dynamical dependence among multiple variables over time. Second, we introduce a robust loss function for time series forecasting to alleviate the potential overfitting issue. This new loss function weights the importance of forecasting over a finite horizon based on prediction uncertainties. Our evaluation of multiple long-term and short-term forecasting datasets demonstrates that CARD significantly outperforms state-of-the-art time series forecasting methods, including both Transformer and MLP-based models.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\Epictus\\Zotero\\storage\\HXW9IP92\\Xue et al_2023_Make Transformer Great Again for Time Series Forecasting.pdf;C\:\\Users\\Epictus\\Zotero\\storage\\GQFHE4IB\\2305.html}
}

@article{xuemeiliNovelDatadrivenSeasonal2023,
  title = {A Novel Data-Driven Seasonal Multivariable Grey Model for Seasonal Time Series Forecasting},
  author = {{Xuemei Li} and {Na Li} and {Song Ding} and {Yun Cao} and {Yao Li}},
  year = {2023},
  month = may,
  journal = {Information Sciences},
  doi = {10.1016/j.ins.2023.119165},
  abstract = {{$<$}p{$>$}Rapid growth in solar power generation, accompanied by random fluctuations, has important implications for the security, stability, and productivity of the grid. Therefore, accurate predictions of solar power generation provide an essential benchmark for relevant institutions to conduct grid planning and power dispatch. Thereby, a novel data-driven seasonal multivariable grey model is proposed for simulating seasonal fluctuations and non-linear trends in solar power generation. To be specific, the novel model contains the following refinements: first, the seasonal factors and time-power item are introduced to modify the insensitivity of traditional multivariable grey models to seasonal fluctuations and non-linear trends. Second, to enhance the generalizability and adaptability of the model, the parameter associated with the time-power item is determined by using the genetic algorithm. Third, on the premise of proving the model's requirements for period length and sample size, the derivation of the time response function is expounded. For illustration and verification purposes, comprehensive experimental studies are conducted with quarterly and monthly time series samples. In addition, forecasts of the novel model are compared with five prevailing models, including grey prediction models, traditional econometric technology, and artificial intelligence. Case studies indicate that this novel model exhibits improved generalizability, stability, and reliability in the face of quarterly or monthly time series data, confirming it as an auspicious and powerful tool for future solar power generation forecasting.{$<$}/p{$>$}},
  copyright = {7.2991},
  lccn = {8.2326}
}

@inproceedings{yanMultibeamDataAutomatic2022,
  title = {Multi-Beam {{Data Automatic Filtering Technology}}},
  booktitle = {2022 3rd {{International Conference}} on {{Geology}}, {{Mapping}} and {{Remote Sensing}} ({{ICGMRS}})},
  author = {Yan, Yu and Yuan, Linfeng and Ran, Longjian and Yin, Hui and Xiao, Xuelu},
  year = {2022},
  month = apr,
  pages = {224--228},
  publisher = {{IEEE}},
  address = {{Zhoushan, China}},
  doi = {10.1109/ICGMRS55602.2022.9849352},
  urldate = {2023-10-14},
  abstract = {Aiming at the characteristics of complex noise sources in multi-beam bathymetric data, this paper proposes a multi-beam automatic filtering method that combines filtering of optimal reference curved surface and trend surface. By implementing statistical filtering to pre-process the data, the optimal reference curved surface is constructed based on the filtered terrain data, the theoretical optimal depth value of each beam point is calculated. The optimal reference curved surface is filtered by combining the depth tolerance to determine whether the point is a noise point. Then the trend surface is constructed using the filtered non-noise data, and the trend surface is filtered on the original point cloud data. Through the verification of the measured data, this method can effectively remove most of the cluster noises in the multi-beam bathymetric data and is more efficient than manual processing.},
  isbn = {978-1-66548-595-1},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\95KAC3HG\Yan ç­‰ - 2022 - Multi-beam Data Automatic Filtering Technology.pdf}
}

@article{yeNovelEnergyConsumption2019,
  title = {A Novel Energy Consumption Forecasting Model Combining an Optimized {{DGM}} (1, 1) Model with Interval Grey Numbers},
  author = {Ye, Jing and Dang, Yaoguo and Ding, Song and Yang, Yingjie},
  year = {2019},
  month = may,
  journal = {Journal of Cleaner Production},
  doi = {10.1016/j.jclepro.2019.04.336},
  abstract = {{$<$}p{$>$}Since energy consumption (EC) is becoming an important issue for sustainable development in the world, it has a practical significance to predict EC effectively. However, there are two main uncertainty factors affecting the accuracy of a region's EC prediction. Firstly, with the ongoing rapid changes in society, the consumption amounts can be non-smooth or even fluctuating during a long time period, which makes it difficult to investigate the sequence's trend in order to forecast. Secondly, in a given region, it is difficult to express the consumption amount as a real number, as there are different development levels in the region, which would be more suitably described as interval numbers. Most traditional prediction models for energy consumption forecasting deal with long-term real numbers. It is seldom found to discover research that focuses specifically on uncertain EC data. To this end, a novel energy consumption forecasting model has been established by expressing ECs in a region as interval grey numbers combining with the optimized discrete grey model (DGM(1,1)) in Grey System Theory (GST). To prove the effectiveness of the method, per capita annual electricity consumption in southern Jiangsu of China is selected as an example. The results show that the proposed model reveals the best accuracy for the short data sequences (the average fitting error is only 2.19\% and the average three-step forecasting error is less than 4\%) compared with three GM models and four classical statistical models. By extension, any fields of EC, such as petroleum consumption, natural gas consumption, can also be predicted using this novel model. As the sustained growth in EC of China's, it is of great significance to predict EC accurately to manage serious energy security and environmental pollution problems, as well as formulating relevant energy policies by the government.{$<$}/p{$>$}},
  copyright = {11.016},
  lccn = {11.072},
  file = {C:\Users\Epictus\Zotero\storage\PVT7HYXZ\Ye et al_2019_A novel energy consumption forecasting model combining an optimized DGM (1, 1).pdf}
}

@article{zengAreTransformersEffective2023,
  title = {Are {{Transformers Effective}} for {{Time Series Forecasting}}?},
  author = {Zeng, Ailing and Chen, Muxi and Zhang, Lei and Xu, Qiang},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {9},
  pages = {11121--11128},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v37i9.26317},
  urldate = {2023-09-14},
  abstract = {Recently, there has been a surge of Transformer-based solutions for the long-term time series forecasting (LTSF) task. Despite the growing performance over the past few years, we question the validity of this line of research in this work. Specifically, Transformers is arguably the most successful solution to extract the semantic correlations among the elements in a long sequence. However, in time series modeling, we are to extract the temporal relations in an ordered set of continuous points. While employing positional encoding and using tokens to embed sub-series in Transformers facilitate preserving some ordering information, the nature of the permutationinvariant self-attention mechanism inevitably results in temporal information loss.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\QVN2N98K\Zeng ç­‰ - 2023 - Are Transformers Effective for Time Series Forecas.pdf}
}

@misc{zhanDifferentialConvolutionalFuzzy2023,
  title = {Differential {{Convolutional Fuzzy Time Series Forecasting}}},
  author = {Zhan, Tianxiang and He, Yuanpeng and Deng, Yong and Li, Zhen},
  year = {2023},
  month = may,
  number = {arXiv:2305.08890},
  eprint = {2305.08890},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-05-27},
  abstract = {Fuzzy time series forecasting (FTSF) is a typical forecasting method with wide application. Traditional FTSF is regarded as an expert system which leads to lose the ability to recognize undefined feature. The mentioned is main reason of poor forecasting with FTSF. To solve the problem, the proposed model Differential Fuzzy Convolutional Neural Network (DFCNN) utilizes convolution neural network to re-implement FTSF with learnable ability. DFCNN is capable of recognizing the potential information and improve the forecasting accuracy. Thanks to learnable ability of neural network, length of fuzzy rules established in FTSF is expended to arbitrary length which expert is not able to be handle by expert system. At the same time, FTSF usually cannot achieve satisfactory performance of non-stationary time series due to trend of non-stationary time series. The trend of non-stationary time series causes the fuzzy set established by FTSF to invalid and cause the forecasting to fail. DFCNN utilizes the Difference algorithm to weaken the non-stationarity of time series, so that DFCNN can forecast the non-stationary time series with low error that FTSF cannot forecast in satisfactory performance. After mass of experiments, DFCNN has excellent prediction effect, which is ahead of the existing FTSF and common time series forecasting algorithms. Finally, DFCNN provides further ideas for improving FTSF and holds continued research value.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\Epictus\\Zotero\\storage\\THSCGYGU\\Zhan et al_2023_Differential Convolutional Fuzzy Time Series Forecasting.pdf;C\:\\Users\\Epictus\\Zotero\\storage\\B2LDTDC6\\2305.html}
}

@article{zhangCROSSFORMERTRANSFORMERUTILIZING2023,
  title = {{{CROSSFORMER}}: {{TRANSFORMER UTILIZING CROSS- DIMENSION DEPENDENCY FOR MULTIVARIATE TIME SERIES FORECASTING}}},
  author = {Zhang, Yunhao and Yan, Junchi},
  year = {2023},
  abstract = {Recently many deep models have been proposed for multivariate time series (MTS) forecasting. In particular, Transformer-based models have shown great potential because they can capture long-term dependency. However, existing Transformerbased models mainly focus on modeling the temporal dependency (cross-time dependency) yet often omit the dependency among different variables (crossdimension dependency), which is critical for MTS forecasting. To fill the gap, we propose Crossformer, a Transformer-based model utilizing cross-dimension dependency for MTS forecasting. In Crossformer, the input MTS is embedded into a 2D vector array through the Dimension-Segment-Wise (DSW) embedding to preserve time and dimension information. Then the Two-Stage Attention (TSA) layer is proposed to efficiently capture the cross-time and cross-dimension dependency. Utilizing DSW embedding and TSA layer, Crossformer establishes a Hierarchical Encoder-Decoder (HED) to use the information at different scales for the final forecasting. Extensive experimental results on six real-world datasets show the effectiveness of Crossformer against previous state-of-the-arts.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\N4Q35YKQ\Zhang å’Œ Yan - 2023 - CROSSFORMER TRANSFORMER UTILIZING CROSS- DIMENSIO.pdf}
}

@article{zhangDigitalProductImports2023,
  title = {Digital Product Imports and Export Product Quality: {{Firm-level}} Evidence from {{China}}},
  shorttitle = {Digital Product Imports and Export Product Quality},
  author = {Zhang, Hongsheng and Liu, Qingqing and Wei, Yueling},
  year = {2023},
  month = jun,
  journal = {China Economic Review},
  volume = {79},
  pages = {101981},
  issn = {1043951X},
  doi = {10.1016/j.chieco.2023.101981},
  urldate = {2023-05-04},
  abstract = {Based on the Statistical Classification of the Digital Economy and Its Core Industries (2021) released by the National Bureau of Statistics of China and the information and communications technology products released by the United Nations Conference on Trade and Development to construct a digital product catalog manually, this paper analyzes the impact of digital product imports on Chinese firms' export product quality using a combined data set of the Annual Survey of In\- dustrial Production and China Custom Records from 2000 to 2013. The results show that digital product imports have a significant positive effect on a firm's export product quality. To address potential endogeneity, this paper uses a series of instrumental variables (IVs) and constructs a multi-timing difference-in-differences model using the firm's first digital product import as exogenous shock, and finds strong supporting evidence. Digital product imports improve the quality of export products through three mechanisms: technology spillovers, productivity, and information-searching capabilities. Heterogeneity analysis reveals that digital product imports have greater impacts on foreign-owned and capital-intensive firms, and digital intermediate imports play a bigger role than do digital non-intermediate imports. The results of this paper have important implications for developing countries that wish to improve the quality of exports through digital trade.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\VPV7HNIL\Zhang ç­‰ - 2023 - Digital product imports and export product quality.pdf}
}

@article{zhangForecastStructuralCharacteristics2023,
  title = {Forecast and Structural Characteristics of {{China}}'s Oil Product Consumption Embedded in Bottom-Line Thinking},
  author = {Zhang, Xiaokong and Chai, Jian and Tian, Lingyue and Yang, Ying and Zhang, Zhe George and Pan, Yue},
  year = {2023},
  month = sep,
  journal = {Energy},
  volume = {278},
  pages = {127889},
  issn = {03605442},
  doi = {10.1016/j.energy.2023.127889},
  urldate = {2023-05-27},
  abstract = {How to judge the bottom line of China's oil product consumption is of great significance for energy security. We innovatively divide oil product consumption into bottom-line and non-bottom-line consumption and use the DMA method for forecasting. The results show that bottom-line consumption of oil products will reach 197.29{\textendash}213.47 Mt in 2025 under the low development scenario, while it will increase to 236.21{\textendash}250.37 Mt and 269.62{\textendash}285.8 Mt in the baseline and high development scenarios, respectively. By reducing the high develop\- ment scenario to the low development scenario, non-bottom-line consumption of oil products can save about 22.09{\textendash}25.32 Mt. The wide variation in the forecast results under the multi-dimensional scenarios reflects the flexibility and feasibility of future policy combinations to regulate oil consumption. Meanwhile, for any oil product, any combination of policy scenarios will control bottom-line and non-bottom-line consumption in the same direction but with different impact effects. Gasoline, kerosene, and diesel will account for a lower limit of about 44\%, 14\%, and 27\%, respectively, in 2025.},
  copyright = {8.2338},
  langid = {english},
  lccn = {8.8569},
  file = {C:\Users\Epictus\Zotero\storage\XFUMFH5B\Zhang ç­‰ - 2023 - Forecast and structural characteristics of China's.pdf}
}

@article{zhangNovelDiscreteMultivariable2022,
  title = {A Novel Discrete Multivariable Grey Model with Spatial Proximity Effects for Economic Output Forecast},
  author = {Zhang, Xu and Dang, Yaoguo and Ding, Song and Wang, Junjie},
  year = {2022},
  month = oct,
  journal = {Applied Mathematical Modelling},
  doi = {10.1016/j.apm.2022.10.041},
  abstract = {{$<$}p{$>$}The temporal and spatial characteristics of the collected data typically play an essential role in time series forecasting. However, traditional grey models pay more attention to temporal information, meanwhile disregarding the presence of spatial features critical to producing accurate forecasts. Moreover, the grey theory has few attempts to overcome this problem. Given this situation, this paper proposes a novel multivariable grey prediction model considering the spatial proximity effect for time series forecasting. More specifically, the complete spatial distance index is defined initially based on the geographical and economic distance to quantify the intensity of the spatial proximity impact. On this basis, the spatial proximity effect term is constructed and incorporated into the conventional discrete multivariable grey model, establishing the novel model. Subsequently, the particle swarm optimization algorithm determines the optimal weight coefficient in the developed index. For illustration and verification purposes, the proposed model performs experiments predicting Jiangsu's economic outputs compared to five prevalent benchmarks. Furthermore, three statistical metrics, the Diebold-Mariano test, the Monte Carlo experiments, and the probability density analysis are employed to validate the model's efficacy and robustness. Empirical results demonstrate that the proposed method outperforms all five competitors with strong robustness and broad generalization. Therefore, this new model is used for forecasting Jiangsu's future economic outputs from 2021 to 2025.{$<$}/p{$>$}},
  lccn = {5.336}
}

@article{zhangPowerConsumptionPredicting2021,
  title = {Power {{Consumption Predicting}} and {{Anomaly Detection Based}} on {{Transformer}} and {{K-Means}}},
  author = {Zhang, Junfeng and Zhang, Hui and Ding, Song and Zhang, Xiaoxiong},
  year = {2021},
  month = oct,
  journal = {Frontiers in Energy Research},
  doi = {10.3389/fenrg.2021.779587},
  abstract = {{$<$}p{$>$}With the advancement of technology and science, the power system is getting more intelligent and flexible, and the way people use electric energy in their daily lives is changing. Monitoring the condition of electrical energy loads, particularly in the early detection of aberrant loads and behaviors, is critical for power grid maintenance and power theft detection. In this paper, we combine the widely used deep learning model Transformer with the clustering approach K-means to estimate power consumption over time and detect anomalies. The Transformer model is used to forecast the following hour's power usage, and the K-means clustering method is utilized to optimize the prediction results, finally, the anomalies is detected by comparing the predicted value and the test value. On real hourly electric energy consumption data, we test the proposed model, and the results show that our method outperforms the most commonly used LSTM time series model.{$<$}/p{$>$}},
  copyright = {4.597},
  lccn = {3.858}
}

@article{zhaoDetectingChangepointTrend2019,
  title = {Detecting Change-Point, Trend, and Seasonality in Satellite Time Series Data to Track Abrupt Changes and Nonlinear Dynamics: {{A Bayesian}} Ensemble Algorithm},
  shorttitle = {Detecting Change-Point, Trend, and Seasonality in Satellite Time Series Data to Track Abrupt Changes and Nonlinear Dynamics},
  author = {Zhao, Kaiguang and Wulder, Michael A. and Hu, Tongxi and Bright, Ryan and Wu, Qiusheng and Qin, Haiming and Li, Yang and Toman, Elizabeth and Mallick, Bani and Zhang, Xuesong and Brown, Molly},
  year = {2019},
  month = oct,
  journal = {Remote Sensing of Environment},
  volume = {232},
  pages = {111181},
  issn = {00344257},
  doi = {10.1016/j.rse.2019.04.034},
  urldate = {2023-11-12},
  abstract = {Satellite time-series data are bolstering global change research, but their use to elucidate land changes and vegetation dynamics is sensitive to algorithmic choices. Different algorithms often give inconsistent or sometimes conflicting interpretations of the same data. This lack of consensus has adverse implications and can be mitigated via ensemble modeling, an algorithmic paradigm that combines many competing models rather than choosing only a single ``best'' model. Here we report one such time-series decomposition algorithm for deriving nonlinear ecosystem dynamics across multiple timescales{\textemdash}A Bayesian Estimator of Abrupt change, Seasonal change, and Trend (BEAST). As an ensemble algorithm, BEAST quantifies the relative usefulness of individual decomposition models, leveraging all the models via Bayesian model averaging. We tested it upon simulated, Landsat, and MODIS data. BEAST detected changepoints, seasonality, and trends in the data reliably; it derived realistic nonlinear trends and credible uncertainty measures (e.g., occurrence probability of changepoints over time){\textemdash}some information difficult to derive by conventional single-best-model algorithms but critical for interpretation of ecosystem dynamics and detection of low-magnitude disturbances. The combination of many models enabled BEAST to alleviate model misspecification, address algorithmic uncertainty, and reduce overfitting. BEAST is generically applicable to time-series data of all kinds. It offers a new analytical option for robust changepoint detection and nonlinear trend analysis and will help exploit environmental time-series data for probing patterns and drivers of ecosystem dynamics.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\RWY7XXRX\Zhao ç­‰ - 2019 - Detecting change-point, trend, and seasonality in .pdf}
}

@misc{zhaoInterpretationTimeSeriesDeep2023,
  title = {Interpretation of {{Time-Series Deep Models}}: {{A Survey}}},
  shorttitle = {Interpretation of {{Time-Series Deep Models}}},
  author = {Zhao, Ziqi and Shi, Yucheng and Wu, Shushan and Yang, Fan and Song, Wenzhan and Liu, Ninghao},
  year = {2023},
  month = may,
  number = {arXiv:2305.14582},
  eprint = {2305.14582},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-06-04},
  abstract = {Deep learning models developed for time-series associated tasks have become more widely researched nowadays. However, due to the unintuitive nature of time-series data, the interpretability problem -- where we understand what is under the hood of these models -- becomes crucial. The advancement of similar studies in computer vision has given rise to many post-hoc methods, which can also shed light on how to explain time-series models. In this paper, we present a wide range of post-hoc interpretation methods for time-series models based on backpropagation, perturbation, and approximation. We also want to bring focus onto inherently interpretable models, a novel category of interpretation where human-understandable information is designed within the models. Furthermore, we introduce some common evaluation metrics used for the explanations, and propose several directions of future researches on the time-series interpretability problem. As a highlight, our work summarizes not only the well-established interpretation methods, but also a handful of fairly recent and under-developed techniques, which we hope to capture their essence and spark future endeavours to innovate and improvise.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
}

@inproceedings{zhaoMultibeamBathymetricMeasurement2022,
  title = {Multi-Beam {{Bathymetric}} Measurement Error Analysis Based on {{Integrated Navigation System}}},
  booktitle = {2022 {{International Seminar}} on {{Computer Science}} and {{Engineering Technology}} ({{SCSET}})},
  author = {Zhao, Wangyang and Zhuang, Xinwei and Wang, Xingling and Zhou, Lingfeng},
  year = {2022},
  month = jan,
  pages = {174--178},
  publisher = {{IEEE}},
  address = {{Indianapolis, IN, USA}},
  doi = {10.1109/SCSET55041.2022.00049},
  urldate = {2023-10-14},
  isbn = {978-1-66547-876-2},
  file = {C:\Users\Epictus\Zotero\storage\9SS6758G\Zhao ç­‰ - 2022 - Multi-beam Bathymetric measurement error analysis .pdf}
}

@article{zhouFEDformerFrequencyEnhanced,
  title = {{{FEDformer}}: {{Frequency Enhanced Decomposed Transformer}} for {{Long-term Series Forecasting}}},
  author = {Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Wang, Xue and Sun, Liang and Jin, Rong},
  abstract = {Although Transformer-based methods have significantly improved state-of-the-art results for long-term series forecasting, they are not only computationally expensive but more importantly, are unable to capture the global view of time series (e.g. overall trend). To address these problems, we propose to combine Transformer with the seasonal-trend decomposition method, in which the decomposition method captures the global profile of time series while Transformers capture more detailed structures. To further enhance the performance of Transformer for long-term prediction, we exploit the fact that most time series tend to have a sparse representation in well-known basis such as Fourier transform, and develop a frequency enhanced Transformer. Besides being more effective, the proposed method, termed as Frequency Enhanced Decomposed Transformer (FEDformer), is more efficient than standard Transformer with a linear complexity to the sequence length. Our empirical studies with six benchmark datasets show that compared with state-of-the-art methods, FEDformer can reduce prediction error by 14.8\% and 22.6\% for multivariate and univariate time series, respectively . Code is publicly available at https://github.com/MAZiqing/FEDformer.},
  langid = {english},
  file = {C:\Users\Epictus\Zotero\storage\N54DFQHJ\Zhou ç­‰ - FEDformer Frequency Enhanced Decomposed Transform.pdf}
}

@misc{zhouInformerEfficientTransformer2021,
  title = {Informer: {{Beyond Efficient Transformer}} for {{Long Sequence Time-Series Forecasting}}},
  shorttitle = {Informer},
  author = {Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
  year = {2021},
  month = mar,
  number = {arXiv:2012.07436},
  eprint = {2012.07436},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-09-19},
  abstract = {Many real-world applications require the prediction of long sequence time-series, such as electricity consumption planning. Long sequence time-series forecasting (LSTF) demands a high prediction capacity of the model, which is the ability to capture precise long-range dependency coupling between output and input efficiently. Recent studies have shown the potential of Transformer to increase the prediction capacity. However, there are several severe issues with Transformer that prevent it from being directly applicable to LSTF, including quadratic time complexity, high memory usage, and inherent limitation of the encoder-decoder architecture. To address these issues, we design an efficient transformer-based model for LSTF, named Informer, with three distinctive characteristics: (i) a ProbSparse self-attention mechanism, which achieves O(L log L) in time complexity and memory usage, and has comparable performance on sequences' dependency alignment. (ii) the self-attention distilling highlights dominating attention by halving cascading layer input, and efficiently handles extreme long input sequences. (iii) the generative style decoder, while conceptually simple, predicts the long time-series sequences at one forward operation rather than a step-by-step way, which drastically improves the inference speed of long-sequence predictions. Extensive experiments on four large-scale datasets demonstrate that Informer significantly outperforms existing methods and provides a new solution to the LSTF problem.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {C:\Users\Epictus\Zotero\storage\MMWVVZU4\Zhou ç­‰ - 2021 - Informer Beyond Efficient Transformer for Long Se.pdf}
}

@article{zhouNovelDiscreteGrey2020,
  title = {A Novel Discrete Grey Seasonal Model and Its Applications},
  author = {Zhou, Weijie and Ding, Song},
  year = {2020},
  month = aug,
  journal = {Communications in Nonlinear Science and Numerical Simulation},
  doi = {10.1016/j.cnsns.2020.105493},
  abstract = {{$<$}p{$>$}In order to accurately describe real systems with seasonal disturbances, which normally appear monthly or quarterly cycles, a novel discrete grey seasonal model, abbreviated as {$<$}em{$>$}DGSM{$<$}/em{$>$}(1, 1), is put forward by incorporating the seasonal dummy variables into the conventional model. Moreover, the mechanism and properties of this proposed model are discussed in depth, revealing the inherent differences from the existing seasonal grey models. For validation and explanation purposes, the proposed model is implemented to describe three actual cases with monthly and quarterly seasonal fluctuations (quarterly wind power production, quarterly PM\textsubscript{10}, and monthly natural gas consumption), in comparison with five competing models involving grey prediction models, conventional econometric technology, and artificial intelligences. Experimental results from the cases consistently demonstrate that the proposed model significantly outperforms the other benchmark models in terms of several error criteria. Moreover, further discussions about the influences of different sequence lengths on the forecasting performance reveal that the proposed model still performs the best with strong robustness and high reliability in addressing seasonal sequences. In general, the new model is validated to be a powerful and promising methodology for handling sequences with seasonal fluctuations.{$<$}/p{$>$}},
  copyright = {4.0151},
  lccn = {4.1857},
  file = {C:\Users\Epictus\Zotero\storage\AVU4QZ2D\Zhou_Ding_2020_A novel discrete grey seasonal model and its applications.pdf}
}

@article{zhouPredictionsMitigationStrategies2021,
  title = {Predictions and Mitigation Strategies of {{PM2}}.5 Concentration in the {{Yangtze River Delta}} of {{China}} Based on a Novel Nonlinear Seasonal Grey Model},
  author = {Zhou, Weijie and Wu, Xiaoli and Ding, Song and Ji, Xiaoli and Pan, Weiqiang},
  year = {2021},
  month = feb,
  journal = {Environmental Pollution},
  doi = {10.1016/j.envpol.2021.116614},
  abstract = {{$<$}p{$>$}High delicate particulate matter (PM\textsubscript{2.5}) concentration can seriously reduce air quality, destroy the environment, and even jeopardize human health. Accordingly, accurate prediction for PM\textsubscript{2.5} plays a vital role in taking precautions against upcoming air ambient pollution incidents. However, due to the disturbance of seasonal and nonlinear characteristics in the raw series, pronounced forecasts are confronted with tremendous handicaps, even though for seasonal grey prediction models in the preceding researches. A novel seasonal nonlinear grey model is initially designed to address such issues by integrating the seasonal adjustment factor, the conventional Weibull Bernoulli grey model, and the cultural algorithm, simultaneously depicting the seasonality and nonlinearity of the original data. Experimental results from PM\textsubscript{2.5} forecasting of four major cities (Shanghai, Nanjing, Hangzhou, and Hefei) in the YRD validate that the proposed model can obtain more accurate predictive results and stronger robustness, in comparison with grey prediction models ({$<$}em{$>$}SNGBM(1,1){$<$}/em{$>$} and {$<$}em{$>$}SGM(1,1){$<$}/em{$>$}), conventional econometric technology ({$<$}em{$>$}SARIMA{$<$}/em{$>$}), and machine learning methods ({$<$}em{$>$}LSSVM{$<$}/em{$>$} and {$<$}em{$>$}BPNN{$<$}/em{$>$}) by employing accuracy levels. Finally, the future PM\textsubscript{2.5} concentration is forecasted from 2020 to 2022 using the proposed model, which provides early warning information for policy-makers to develop PM\textsubscript{2.5} alleviation strategies.{$<$}/p{$>$}},
  file = {C:\Users\Epictus\Zotero\storage\3PN5T839\Zhou et al_2021_Predictions and mitigation strategies of PM2.pdf}
}

@article{zhuIntervalForecastingCarbon2022,
  title = {Interval Forecasting of Carbon Price: {{A}} Novel Multiscale Ensemble Forecasting Approach},
  shorttitle = {Interval Forecasting of Carbon Price},
  author = {Zhu, Bangzhu and Wan, Chunzhuo and Wang, Ping},
  year = {2022},
  month = nov,
  journal = {Energy Economics},
  volume = {115},
  pages = {106361},
  issn = {01409883},
  doi = {10.1016/j.eneco.2022.106361},
  urldate = {2023-02-22},
  abstract = {Aiming at the limitations of carbon price point forecasting, we propose a novel integrated approach of binary empirical mode decomposition (BEMD), differential evolution (DE) algorithm, and extreme gradient boosting (XGB) for carbon price interval forecasting. Firstly, BEMD, which is suitable for interval time series, is introduced into decomposing complex carbon data into simple components. Secondly, XGB is used to forecast the obtained components, and DE is used to synchronously optimize all parameters of XGB. Thirdly, the individual component forecasting values are aggregated into carbon price forecasting values. Taking Guangdong and Hubei carbon markets as samples, in comparison with other popular prediction models, the proposed approach has a higher coverage rate and lower prediction error. The sensitivity analysis verifies that the proposed approach is robust.},
  copyright = {9.4891},
  langid = {english},
  lccn = {9.2517},
  file = {C:\Users\Epictus\Zotero\storage\9ZLHZ9TF\Zhu ç­‰ - 2022 - Interval forecasting of carbon price A novel mult.pdf}
}
